{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Clone Dataset Overview\n",
    "\n",
    "- novel isoforms\n",
    "- summary of assay results\n",
    "- assay validations\n",
    "- network plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import met_brewer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from Bio.PDB.DSSP import make_dssp_dict\n",
    "from Bio.Data.IUPACData import protein_letters_3to1\n",
    "\n",
    "# import utils\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data_loading import (load_annotated_TFiso1_collection,\n",
    "                          load_y2h_isoform_data,\n",
    "                          load_y1h_pdi_data,\n",
    "                          load_m1h_activation_data,\n",
    "                          load_annotated_gencode_tfs,\n",
    "                          load_developmental_tissue_expression_remapped,\n",
    "                          load_gtex_remapped,\n",
    "                          load_tf_families,\n",
    "                          load_full_y2h_data_including_controls,\n",
    "                          load_ref_vs_alt_isoforms_table,\n",
    "                          load_PDI_luciferase_validation_experiment,\n",
    "                          load_n2h_ppi_validation_data,\n",
    "                          load_Y1H_DNA_bait_sequences,\n",
    "                          load_valid_isoform_clones,\n",
    "                          load_ppi_partner_categories,\n",
    "                          load_DNA_binding_domains,\n",
    "                          )\n",
    "from plotting import (mimic_r_boxplot, \n",
    "                      validation_titration_plot, \n",
    "                      validation_plot, \n",
    "                      violinplot_reflected, \n",
    "                      annotate_pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_PRESET = {\"style\": \"ticks\", \"font\": \"Helvetica\", \"context\": \"paper\", \n",
    "                \"rc\": {\"font.size\":7,\"axes.titlesize\":7,\n",
    "                     \"pdf.fonttype\": 42, \n",
    "                       \"axes.labelsize\":7, 'axes.linewidth':0.5,\n",
    "                       \"legend.fontsize\":6, \"xtick.labelsize\":6,\n",
    "                       \"ytick.labelsize\":6, \"xtick.major.size\": 3.0,\n",
    "                       \"ytick.major.size\": 3.0, \"axes.edgecolor\": \"black\",\n",
    "                       \"xtick.major.pad\": 3.0, \"ytick.major.pad\": 3.0}}\n",
    "PAPER_FONTSIZE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(**PAPER_PRESET)\n",
    "fontsize = PAPER_FONTSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load clone collection, gencode TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genc_tfs = load_annotated_gencode_tfs()\n",
    "\n",
    "clone_tfs = load_annotated_TFiso1_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(genc_tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clone_tfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. count number of splicing categories across gencode and cloned TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_splicing_types(tfs, index):\n",
    "    \n",
    "    alt_n = 0\n",
    "    alt_c = 0\n",
    "    alt_int = 0\n",
    "    alt_5ss = 0\n",
    "    alt_3ss = 0\n",
    "    exon_sk = 0\n",
    "    mut_ex = 0\n",
    "    intron_ret = 0\n",
    "    tot = 0\n",
    "\n",
    "    for tf in tfs.keys():\n",
    "        gene = tfs[tf]\n",
    "        if index == \"gencode\":\n",
    "            ref = gene.reference_isoform.name\n",
    "            alts = [x.name for x in gene.alternative_isoforms]\n",
    "        elif index == \"TFIso1.0\":\n",
    "            ref = gene.cloned_reference_isoform.name\n",
    "            alts = [x.name for x in gene.cloned_isoforms if x.name != ref]\n",
    "        elif index == \"TFIso1.0 - novel\":\n",
    "            ref = gene.cloned_reference_isoform.name\n",
    "            alts = [x.name for x in gene.cloned_isoforms if x.is_novel_isoform()]\n",
    "        elif index == \"TFIso1.0 - annotated\":\n",
    "            ref = gene.cloned_reference_isoform.name\n",
    "            alts = [x.name for x in gene.cloned_isoforms if not x.is_novel_isoform() and x.name != ref]\n",
    "        for alt in alts:\n",
    "            splicing_cats = gene.splicing_categories(ref, alt)\n",
    "\n",
    "            if splicing_cats['alternative N-terminal']:\n",
    "                alt_n += 1\n",
    "            if splicing_cats['alternative C-terminal']:\n",
    "                alt_c += 1\n",
    "            if splicing_cats['alternative internal exon']:\n",
    "                alt_int += 1\n",
    "            if splicing_cats['alternative 5\\' splice site']:\n",
    "                alt_5ss += 1\n",
    "            if splicing_cats['alternative 3\\' splice site']:\n",
    "                alt_3ss += 1\n",
    "            if splicing_cats['exon skipping']:\n",
    "                exon_sk += 1\n",
    "            if splicing_cats['mutually exclusive exons']:\n",
    "                mut_ex += 1\n",
    "            if splicing_cats['intron retention']:\n",
    "                intron_ret += 1\n",
    "\n",
    "            tot += 1\n",
    "\n",
    "    df = pd.DataFrame.from_dict({\"alt. N-terminal\": [alt_n], \"alt. C-terminal\": [alt_c],\n",
    "                              \"alt. internal exon\": [alt_int], \"alt. 5' splice site\": [alt_5ss],\n",
    "                              \"alt. 3' splice site\": [alt_3ss], \"exon skipping\": [exon_sk],\n",
    "                              \"mutually exclusive exons\": [mut_ex], \"intron retention\": [intron_ret],\n",
    "                              \"total\": tot})\n",
    "    df.index = [index]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genc_df = count_splicing_types(genc_tfs, \"gencode\")\n",
    "genc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_df = count_splicing_types(clone_tfs, \"TFIso1.0\")\n",
    "clone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_df = count_splicing_types(clone_tfs, \"TFIso1.0 - novel\")\n",
    "novel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = count_splicing_types(clone_tfs, \"TFIso1.0 - annotated\")\n",
    "annotated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splicing = pd.concat([genc_df, annotated_df, novel_df])\n",
    "splicing_tot = splicing[\"total\"]\n",
    "splicing = splicing.drop(\"total\", axis=1)\n",
    "splicing_perc = splicing.divide(splicing_tot, axis='rows').reset_index()\n",
    "splicing_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splicing_perc_melt = pd.melt(splicing_perc, id_vars=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = met_brewer.met_brew(name=\"VanGogh2\")\n",
    "sns.palplot(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.75, 1))\n",
    "\n",
    "ax = sns.barplot(data=splicing_perc_melt, \n",
    "                 x=\"variable\", \n",
    "                 y=\"value\", \n",
    "                 hue=\"index\", \n",
    "                 palette={\"gencode\": colors[2],\n",
    "                          \"TFIso1.0 - novel\": colors[7],\n",
    "                          \"TFIso1.0 - annotated\": colors[4]})\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticklabels(list(splicing_perc_melt[\"variable\"].unique()), \n",
    "                   ha=\"right\", \n",
    "                   va=\"top\", \n",
    "                   rotation=30)\n",
    "ax.set_ylabel(\"Percentage of\\nalternative isoforms\")\n",
    "\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "\n",
    "ax.set_yticks(np.linspace(0, 0.6, 4))\n",
    "ax.set_yticks(np.linspace(0, 0.6, 7), minor=True)\n",
    "ax.set_yticklabels([f'{y:.0%}' for y in ax.get_yticks()])\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/splicing_cats.pdf\", \n",
    "            dpi=\"figure\", \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. expression of novel isoforms compared to annotated ref/alt\n",
    "\n",
    "using the same dummy, downsampled data as in fig1 for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_map = {}\n",
    "\n",
    "# only loop through clone collection\n",
    "for tf in clone_tfs.keys():\n",
    "    gene = clone_tfs[tf]\n",
    "    \n",
    "    try:\n",
    "        annot_ref = gene.reference_isoform.name\n",
    "    except:\n",
    "        annot_ref = \"none\"\n",
    "        \n",
    "    try:\n",
    "        annot_alt = gene.alternative_isoforms\n",
    "    except:\n",
    "        annot_alt = []\n",
    "        \n",
    "    for iso in gene.cloned_isoforms:\n",
    "        if iso.name == annot_ref:\n",
    "            status_map[iso.clone_acc] = {\"gene_name\": tf, \"status\": \"ref\"}\n",
    "        elif iso.is_novel_isoform():\n",
    "            status_map[iso.clone_acc] = {\"gene_name\": tf, \"status\": \"novel\"}\n",
    "        else:\n",
    "            status_map[iso.clone_acc] = {\"gene_name\": tf, \"status\": \"alt\"}\n",
    "\n",
    "status_map = pd.DataFrame.from_dict(status_map, orient=\"index\")\n",
    "status_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = pd.DataFrame(status_map.status.value_counts())\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUM OF ISOFORMS IN TF1.0 THAT MATCH GENCODE ANNOTATIONS: %s\" % (vc.loc[[\"alt\", \"ref\"]][\"count\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUM OF ISOFORMS IN TF1.0 THAT ARE NOVEL: %s\" % (vc.loc[\"novel\"][\"count\"]))\n",
    "print(\"PERCENT OF ISOFORMS IN TF1.0 THAT ARE NOVEL: %s\" % (vc.loc[\"novel\"][\"count\"]/vc[\"count\"].sum()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev, metadata_dev, genes_dev = load_developmental_tissue_expression_remapped()\n",
    "\n",
    "rename_dev_stage = {'8 week post conception,embryo': '08',\n",
    "'11 week post conception,late embryo': '11',\n",
    "'embryo,7 week post conception': '07',\n",
    "'infant': 'infant',\n",
    "'10 week post conception,late embryo': '10',\n",
    "'young adult': 'young adult',\n",
    "'13 week post conception,late embryo': '13',\n",
    "'16 week post conception,late embryo': '16',\n",
    "'4 week post conception,embryo': '04',\n",
    "'neonate': 'neonate',\n",
    "'19 week post conception,late embryo': '19',\n",
    "'9 week post conception,late embryo': '09',\n",
    "'adolescent': 'adolescent',\n",
    "'5 week post conception,embryo': '05',\n",
    "'embryo,6 week post conception': '06',\n",
    "'12 week post conception,late embryo': '12',\n",
    "'18 week post conception,late embryo': '18',\n",
    "'toddler': 'toddler',\n",
    "'elderly': 'elderly',\n",
    "'middle adult': 'adult',\n",
    "'school age child': 'child'}\n",
    "\n",
    "metadata_dev['dev_stage'] = metadata_dev['Developmental_Stage'].map(rename_dev_stage)\n",
    "means_dev = (df_dev.groupby(df_dev.columns.map(metadata_dev['organism_part'] + ' ' + metadata_dev['dev_stage']), axis=1)\n",
    "           .mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtex, metadata_gtex, genes_gtex = load_gtex_remapped()\n",
    "\n",
    "exclusion_list_gtex = {'Cells - Leukemia cell line (CML)',\n",
    "                       'Cells - EBV-transformed lymphocytes',\n",
    "                       'Cells - Cultured fibroblasts'}\n",
    "\n",
    "df_gtex = df_gtex.loc[:, ~df_gtex.columns.map(metadata_gtex['body_site']).isin(exclusion_list_gtex)]\n",
    "metadata_gtex = metadata_gtex.loc[~metadata_gtex['body_site'].isin(exclusion_list_gtex), :]\n",
    "\n",
    "means_gtex = df_gtex.groupby(df_gtex.columns.map(metadata_gtex['body_site']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_gtex_dummy = pd.read_table(\"../../data/processed/metadata_gtex_dummy.csv\", sep=\",\", index_col=0)\n",
    "\n",
    "# use same downsample as fig1\n",
    "means_gtex_downsample = df_gtex.groupby(df_gtex.columns.map(metadata_gtex_dummy['body_site']), axis=1).mean()\n",
    "\n",
    "means_dev[\"median\"] = means_dev.median(axis=1)\n",
    "means_dev[\"max\"] = means_dev.max(axis=1)\n",
    "\n",
    "means_gtex_downsample[\"median\"] = means_gtex_downsample.median(axis=1)\n",
    "means_gtex_downsample[\"max\"] = means_gtex_downsample.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mm = means_dev[[\"median\", \"max\"]].reset_index()\n",
    "gtex_ds_mm = means_gtex_downsample[[\"median\", \"max\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mm[\"clone_acc\"] = dev_mm[\"UID\"].str.split(\" \", expand=True)[0]\n",
    "gtex_ds_mm[\"clone_acc\"] = gtex_ds_mm[\"UID\"].str.split(\" \", expand=True)[0]\n",
    "mm = dev_mm[dev_mm[\"clone_acc\"] != \"noclone\"].merge(gtex_ds_mm[gtex_ds_mm[\"clone_acc\"] != \"noclone\"], \n",
    "                                                    on=\"clone_acc\", suffixes=(\"_dev\", \"_gtex_ds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_map = status_map.reset_index()\n",
    "status_map[\"clone_acc\"] = status_map[\"index\"].str.split(\" \", expand=True)[0]\n",
    "\n",
    "exp_nov = status_map.merge(mm, on=\"clone_acc\")\n",
    "exp_nov_melt = pd.melt(exp_nov, id_vars=[\"index\", \"gene_name\", \"status\", \"clone_acc\"], value_vars=[\"median_dev\",\n",
    "                                                                                                   \"max_dev\",\n",
    "                                                                                                   \"median_gtex_ds\",\n",
    "                                                                                                   \"max_gtex_ds\"])\n",
    "exp_nov_melt[\"measurement\"] = exp_nov_melt[\"variable\"].str.split(\"_\", expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = met_brewer.met_brew(name=\"Monet\")\n",
    "sns.palplot(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.5, 1.5))\n",
    "\n",
    "exp_nov_melt[\"value_log2\"] = np.log2(exp_nov_melt[\"value\"]+1)\n",
    "ax = sns.boxplot(data=exp_nov_melt[exp_nov_melt[\"variable\"].str.contains(\"dev\")], \n",
    "                 x=\"status\", \n",
    "                 y=\"value\", \n",
    "                 hue=\"measurement\", \n",
    "                 palette={\"median\": colors[7],\n",
    "                          \"max\": colors[6]}, \n",
    "                 flierprops={\"marker\": \"o\"}, \n",
    "                 fliersize=4, \n",
    "                 notch=True)\n",
    "\n",
    "mimic_r_boxplot(ax)\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"Clone category\")\n",
    "ax.set_ylabel(\"Isoform expression (TPM)\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/novel_isos.dev_expr_boxplot.pdf\", \n",
    "            dpi=\"figure\", \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.3, 1.4))\n",
    "\n",
    "ax = sns.boxplot(data=exp_nov_melt[exp_nov_melt[\"variable\"].str.contains(\"dev\")], \n",
    "                 x=\"status\", \n",
    "                 y=\"value_log2\", \n",
    "                 hue=\"measurement\", \n",
    "                 palette={\"median\": colors[7],\n",
    "                          \"max\": colors[6]}, \n",
    "                 flierprops={\"marker\": \"o\"}, \n",
    "                 fliersize=4, \n",
    "                 notch=True)\n",
    "\n",
    "mimic_r_boxplot(ax)\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"Clone category\")\n",
    "ax.set_ylabel(\"Isoform expression (TPM)\")\n",
    "\n",
    "ticks = [0, 1, 5, 10, 20, 30]\n",
    "ticklabels = [0, 1, 5, 10, 20, 30]\n",
    "ax.set_yticks([np.log2(y + 1) for y in ticks])\n",
    "ax.set_yticklabels(ticklabels)\n",
    "ax.tick_params(axis='y', labelsize=fontsize-2)\n",
    "ax.set_ylim(0, np.log2(31))\n",
    "plt.title(\"Developmental RNA-seq\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/novel_isos.dev_expr_boxplot.log2.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.2, 1.3))\n",
    "\n",
    "ax = sns.boxplot(data=exp_nov_melt[exp_nov_melt[\"variable\"].str.contains(\"gtex_ds\")], \n",
    "                 x=\"status\", \n",
    "                 y=\"value_log2\", \n",
    "                 hue=\"measurement\", \n",
    "                 palette={\"median\": colors[7],\n",
    "                          \"max\": colors[6]}, \n",
    "                 flierprops={\"marker\": \"o\"}, \n",
    "                 fliersize=4, \n",
    "                 notch=True)\n",
    "\n",
    "mimic_r_boxplot(ax)\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"Clone category\")\n",
    "ax.set_ylabel(\"Isoform expression (TPM)\")\n",
    "ticks = [0, 1, 5, 10, 20, 30, 50]\n",
    "ticklabels = [0, 1, 5, 10, 20, 30, 50]\n",
    "ax.set_yticks([np.log2(y + 1) for y in ticks])\n",
    "ax.set_yticklabels(ticklabels)\n",
    "\n",
    "ax.set_ylim(0, np.log2(51))\n",
    "ax.tick_params(axis='y', labelsize=fontsize-2)\n",
    "plt.title(\"GTEx (down-sampled)\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/novel_isos.gtex_ds_expr_boxplot.log2.pdf\", \n",
    "            dpi=\"figure\", \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.5, 1.5))\n",
    "\n",
    "ax = sns.boxplot(data=exp_nov_melt[exp_nov_melt[\"variable\"].str.contains(\"gtex_ds\")], \n",
    "                 x=\"status\", y=\"value\", hue=\"measurement\", palette={\"median\": colors[7],\n",
    "                                                                    \"max\": colors[6]}, \n",
    "                 flierprops={\"marker\": \"o\"}, fliersize=4, notch=True)\n",
    "\n",
    "mimic_r_boxplot(ax)\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"Clone category\")\n",
    "ax.set_ylabel(\"Isoform expression (TPM)\")\n",
    "\n",
    "\n",
    "plt.title(\"GTEx (down-sampled)\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/novel_isos.gtex_ds_expr_boxplot.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cols = [x for x in means_dev.columns if x not in [\"UID\", \"median\", \"max\"]]\n",
    "means_dev[\"n_over1\"] = (means_dev[dev_cols] >= 1).sum(axis=1)\n",
    "means_dev[\"n_over5\"] = (means_dev[dev_cols] >= 5).sum(axis=1)\n",
    "\n",
    "dev_over = means_dev[[\"n_over1\", \"n_over5\"]].reset_index()\n",
    "\n",
    "dev_over[\"clone_acc\"] = dev_over[\"UID\"].str.split(\" \", expand=True)[0]\n",
    "dev_over = status_map.merge(dev_over, on=\"clone_acc\")\n",
    "dev_over_melt = pd.melt(dev_over, id_vars=[\"index\", \"gene_name\", \"status\", \"clone_acc\", \"UID\"])\n",
    "dev_over_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.2, 1.3))\n",
    "\n",
    "ax = sns.boxplot(data=dev_over_melt, \n",
    "                 x=\"status\", y=\"value\", hue=\"variable\", palette={\"n_over1\": colors[7],\n",
    "                                                                 \"n_over5\": colors[6]}, \n",
    "                 flierprops={\"marker\": \"o\"}, fliersize=4, notch=True)\n",
    "\n",
    "mimic_r_boxplot(ax)\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"Clone category\")\n",
    "ax.set_ylabel(\"# of samples where iso.\\nexpression ≥ threshold\")\n",
    "\n",
    "plt.title(\"Developmental RNA-seq\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/novel_isos.dev_expr_boxplot.n_over_threshold.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtex_ds_cols = [x for x in means_gtex_downsample.columns if x not in [\"UID\", \"median\", \"max\"]]\n",
    "means_gtex_downsample[\"n_over1\"] = (means_gtex_downsample[gtex_ds_cols] >= 1).sum(axis=1)\n",
    "means_gtex_downsample[\"n_over5\"] = (means_gtex_downsample[gtex_ds_cols] >= 5).sum(axis=1)\n",
    "\n",
    "gtex_ds_over = means_gtex_downsample[[\"n_over1\", \"n_over5\"]].reset_index()\n",
    "\n",
    "gtex_ds_over[\"clone_acc\"] = gtex_ds_over[\"UID\"].str.split(\" \", expand=True)[0]\n",
    "gtex_ds_over = status_map.merge(gtex_ds_over, on=\"clone_acc\")\n",
    "gtex_ds_over_melt = pd.melt(gtex_ds_over, id_vars=[\"index\", \"gene_name\", \"status\", \"clone_acc\", \"UID\"])\n",
    "gtex_ds_over.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.2, 1.3))\n",
    "\n",
    "ax = sns.boxplot(data=gtex_ds_over_melt, \n",
    "                 x=\"status\", y=\"value\", hue=\"variable\", palette={\"n_over1\": colors[7],\n",
    "                                                                 \"n_over5\": colors[6]}, \n",
    "                 flierprops={\"marker\": \"o\"}, fliersize=4, notch=True)\n",
    "\n",
    "mimic_r_boxplot(ax)\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"Clone category\")\n",
    "ax.set_ylabel(\"# of samples where iso.\\nexpression ≥ threshold\")\n",
    "\n",
    "plt.title(\"GTEx (down-sampled)\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/novel_isos.gtex_ds_expr_boxplot.n_over_threshold.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. distribution of TF families in clone collection and assays v gencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = load_tf_families()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(genc_tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genc_df = {k: genc_tfs[k].GENCODE_isoforms for k in genc_tfs.keys()}\n",
    "genc_df = {k: [v.name for v in values] for k, values in genc_df.items()}\n",
    "genc_df = [(k, v) for k, sublist in genc_df.items() for v in sublist]\n",
    "genc_df = pd.DataFrame(genc_df, columns=[\"gene\", \"isoform\"])\n",
    "genc_df['family'] = genc_df['gene'].map(fam)\n",
    "genc_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_separate = [\"C2H2 ZF\", \"Homeodomain\", \"bHLH\", \"Nuclear receptor\", \"bZIP\", \"Forkhead\", \"Ets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_family(row):\n",
    "    if row.family in leave_separate:\n",
    "        return row.family\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "genc_df['family_renamed'] = genc_df.apply(rename_family, axis=1)\n",
    "genc_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genc_vc = genc_df.groupby(\"family_renamed\")[\"isoform\"].agg(\"count\").reset_index()\n",
    "genc_vc[\"source\"] = \"GENCODE\"\n",
    "genc_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_df = {k: clone_tfs[k].cloned_isoforms for k in clone_tfs.keys()}\n",
    "clone_df = {k: [v.clone_acc for v in values] for k, values in clone_df.items()}\n",
    "clone_df = [(k, v) for k, sublist in clone_df.items() for v in sublist]\n",
    "clone_df = pd.DataFrame(clone_df, columns=[\"gene\", \"isoform\"])\n",
    "clone_df['family'] = clone_df['gene'].map(fam)\n",
    "clone_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_family(row):\n",
    "    if row.family in leave_separate:\n",
    "        return row.family\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "clone_df['family_renamed'] = clone_df.apply(rename_family, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = clone_df.groupby(\"family\")[\"isoform\"].agg(\"count\").reset_index()\n",
    "order = order.sort_values(by=\"isoform\", ascending=False)\n",
    "xorder = list(order[\"family\"])\n",
    "yvals = list(order[\"isoform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 1.3))\n",
    "\n",
    "ax = sns.countplot(data=clone_df, x=\"family\", order=xorder)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Number of isoform clones\")\n",
    "ax.set_title(\"Families of TF isoforms in clone collection\")\n",
    "ax.set_ylim((0, 370))\n",
    "\n",
    "_= plt.xticks(rotation=90, ha='center', va=\"top\")\n",
    "\n",
    "for i, yval in enumerate(yvals):\n",
    "    ax.text(i, yval, ' %s' % yval, ha='center', va='bottom', rotation=90, fontsize=6)\n",
    "    \n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "    \n",
    "fig.savefig(\"../../figures/fig2/clone_collection_families.all.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_vc = clone_df.groupby(\"family_renamed\")[\"isoform\"].agg(\"count\").reset_index()\n",
    "clone_vc[\"source\"] = \"TFIso1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1h = load_y1h_pdi_data()\n",
    "y1h['family'] = y1h['gene_symbol'].map(fam)\n",
    "y1h['family_renamed'] = y1h.apply(rename_family, axis=1)\n",
    "\n",
    "# limit to only clones considered in tf1.0, e.g. anything for a tf >1 iso\n",
    "y1h = y1h[y1h[\"clone_acc\"].isin(status_map[\"clone_acc\"])]\n",
    "\n",
    "y1h.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baits = [x for x in y1h.columns if x not in ['gene_symbol', 'clone_acc', 'family', 'family_renamed',\n",
    "                                             'any_true', 'all_na']]\n",
    "print(\"NUMBER OF BAITS TESTED IN Y1H: %s\" % len(baits))\n",
    "print(\"number of new baits Anna's paired screen added: %s\" % len([x for x in baits if not x.startswith(\"HS\") and not x.startswith(\"MUT\")]))\n",
    "y1h['any_true'] = y1h[baits].sum(axis=1)\n",
    "y1h['all_na'] = y1h[baits].isnull().values.all()\n",
    "\n",
    "# remove any rows with allna values\n",
    "y1h = y1h[~y1h['all_na']]\n",
    "print(\"NUMBER OF ISOS SUCCESSFULLY TESTED IN Y1H: %s\" % len(y1h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1h_vc = y1h.groupby(\"family_renamed\")[\"clone_acc\"].agg(\"count\").reset_index()\n",
    "y1h_vc.columns = [\"family_renamed\", \"isoform\"]\n",
    "y1h_vc[\"source\"] = \"Y1H (all)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1h_any_vc = y1h[y1h['any_true'] > 0].groupby(\"family_renamed\")[\"clone_acc\"].agg(\"count\").reset_index()\n",
    "y1h_any_vc.columns = [\"family_renamed\", \"isoform\"]\n",
    "y1h_any_vc[\"source\"] = \"Y1H (≥1 PDI)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2h = load_y2h_isoform_data(require_at_least_one_ppi_per_isoform=False)\n",
    "y2h['family'] = y2h['ad_gene_symbol'].map(fam)\n",
    "y2h['family_renamed'] = y2h.apply(rename_family, axis=1)\n",
    "\n",
    "# limit to only clones considered in tf1.0, e.g. anything for a tf >1 iso\n",
    "y2h = y2h[y2h[\"ad_clone_acc\"].isin(status_map[\"clone_acc\"])]\n",
    "\n",
    "# remove any rows with na values\n",
    "print(len(y2h))\n",
    "y2h = y2h[~pd.isnull(y2h['Y2H_result'])]\n",
    "print(len(y2h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2h_vc = y2h.groupby(\"family_renamed\")[\"ad_clone_acc\"].agg(\"count\").reset_index()\n",
    "y2h_vc.columns = [\"family_renamed\", \"isoform\"]\n",
    "y2h_vc[\"source\"] = \"Y2H (all)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2h_any_vc = y2h[y2h[\"Y2H_result\"] == True].groupby(\"family_renamed\")[\"ad_clone_acc\"].agg(\"count\").reset_index()\n",
    "y2h_any_vc.columns = [\"family_renamed\", \"isoform\"]\n",
    "y2h_any_vc[\"source\"] = \"Y2H (≥1 PPI)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1h = load_m1h_activation_data()\n",
    "m1h['M1H_mean'] = m1h[['M1H_rep1', 'M1H_rep2', 'M1H_rep3']].mean(axis=1)\n",
    "m1h['family'] = m1h['gene_symbol'].map(fam)\n",
    "m1h['family_renamed'] = m1h.apply(rename_family, axis=1)\n",
    "\n",
    "# limit to only clones considered in tf1.0, e.g. anything for a tf >1 iso\n",
    "m1h = m1h[m1h[\"clone_acc\"].isin(status_map[\"clone_acc\"])]\n",
    "\n",
    "m1h.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUM ISOS TESTED IN M1H: %s\" % (len(m1h[~pd.isnull(m1h[\"M1H_mean\"])].clone_acc.unique())))\n",
    "print(\"NUM GENES TESTED IN M1H: %s\" % (len(m1h[~pd.isnull(m1h[\"M1H_mean\"])].gene_symbol.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1h_vc = m1h.groupby(\"family_renamed\")[\"clone_acc\"].agg(\"count\").reset_index()\n",
    "m1h_vc.columns = [\"family_renamed\", \"isoform\"]\n",
    "m1h_vc[\"source\"] = \"M1H (all)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1h_any_vc = m1h[m1h[\"M1H_mean\"].abs() > 1].groupby(\"family_renamed\")[\"clone_acc\"].agg(\"count\").reset_index()\n",
    "m1h_any_vc.columns = [\"family_renamed\", \"isoform\"]\n",
    "m1h_any_vc[\"source\"] = \"M1H (≥2-fold activ.)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_vc = pd.concat([genc_vc, clone_vc, y1h_vc, y1h_any_vc, y2h_vc, y2h_any_vc, m1h_vc, m1h_any_vc])\n",
    "mrg_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_piv = pd.pivot_table(mrg_vc, values=\"isoform\", columns=\"source\", index=\"family_renamed\")\n",
    "mrg_piv = mrg_piv.fillna(0)\n",
    "mrg_piv = (mrg_piv/mrg_piv.sum(axis=0))*100\n",
    "mrg_piv = mrg_piv.T\n",
    "mrg_piv = mrg_piv.reindex([\"GENCODE\", \"TFIso1.0\", \"Y1H (all)\", \"Y1H (≥1 PDI)\",\n",
    "                           \"Y2H (all)\", \"Y2H (≥1 PPI)\", \"M1H (all)\", \"M1H (≥2-fold activ.)\"])\n",
    "mrg_piv = mrg_piv.reset_index()\n",
    "\n",
    "mrg_piv = mrg_piv[[\"source\", \"Other\", \"Ets\", \"Forkhead\", \"bZIP\", \"Nuclear receptor\",\n",
    "                   \"bHLH\", \"Homeodomain\", \"C2H2 ZF\"]]\n",
    "mrg_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = met_brewer.met_brew(name=\"Hokusai1\")\n",
    "colors.append(\"lightgrey\")\n",
    "colors = colors[::-1]\n",
    "#colors[7] = \"lightgrey\"\n",
    "sns.palplot(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = mrg_piv.plot.bar(x=\"source\", stacked=True, color=colors, figsize=(1.5, 1.5))\n",
    "\n",
    "ax.set_ylabel(\"Percentage of isoforms\")\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "plt.legend()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(reversed(handles), reversed(labels), loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "plt.savefig('../../figures/fig2/assay_families.detailed.pdf',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = mrg_piv[mrg_piv[\"source\"].isin([\"GENCODE\", \"TFIso1.0\", \"Y1H (all)\",\n",
    "                  \"Y2H (all)\", \"M1H (all)\"])].plot.bar(x=\"source\", stacked=True, color=colors, figsize=(1.1, 1.5))\n",
    "\n",
    "ax.set_ylabel(\"Percentage of isoforms\")\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "plt.legend()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(reversed(handles), reversed(labels), loc=2, bbox_to_anchor=(1.01, 1), borderpad=0.25,\n",
    "          handlelength=1, handletextpad=0.2, frameon=False)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks(range(0, 101, 20))\n",
    "ax.set_yticks(range(0, 101, 10), minor=True)\n",
    "\n",
    "plt.savefig('../../figures/fig2/assay_families.pdf',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. print number of genes/isos in each category for use in schematic figs/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of isos in collection\")\n",
    "len(clone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of unique TF genes in collection\")\n",
    "len(clone_df.gene.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of isos tested in Y1H\")\n",
    "len(y1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of unique TF genes tested in Y1H\")\n",
    "len(y1h.gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of baits tested in Y1H\")\n",
    "len(baits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of isos with at least 1 interaction in Y1H\")\n",
    "len(y1h[y1h['any_true'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of unique TF genes with at least 1 interaction in Y1H\")\n",
    "len(y1h[y1h['any_true'] > 0].gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of isos tested in Y2H\")\n",
    "len(y2h[~pd.isnull(y2h[\"Y2H_result\"])].ad_clone_acc.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of unique TF genes tested in Y2H\")\n",
    "len(y2h[~pd.isnull(y2h[\"Y2H_result\"])].ad_gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of partners tested in Y2H\")\n",
    "len(y2h.db_gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of isos with at least 1 interaction in Y2H\")\n",
    "len(y2h[y2h[\"Y2H_result\"] == True].ad_clone_acc.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of unique TF genes with at least 1 interaction in Y2H\")\n",
    "len(y2h[y2h[\"Y2H_result\"] == True].ad_gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of isos tested in M1H\")\n",
    "len(m1h.clone_acc.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of unique TF genes tested in M1H\")\n",
    "len(m1h.gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of isos with activity in M1H (abs > 1)\")\n",
    "len(m1h[m1h[\"M1H_mean\"].abs() > 1].clone_acc.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total # of unique TF genes with activity in M1H (abs > 1)\")\n",
    "len(m1h[m1h[\"M1H_mean\"].abs() > 1].gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_3 = set(m1h[m1h[\"M1H_mean\"].abs() > 1].gene_symbol.unique()).intersection(set(y2h[y2h[\"Y2H_result\"] == True].ad_gene_symbol.unique())).intersection(set(y1h[y1h['any_true'] > 0].gene_symbol.unique()))\n",
    "all_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. compare novel isoform performance in assay to annotated ref/alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import load_valid_isoform_clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mane_select_clones = {tf.MANE_select_isoform.clone_acc for tf in clone_tfs.values() \n",
    "                      if tf.cloned_MANE_select_isoform}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = load_valid_isoform_clones()\n",
    "iso['is_longest_isoform'] = iso['clone_acc'].isin(iso.sort_values('num_aa', \n",
    "                                                                  ascending=False).groupby('gene_symbol').nth(0)['clone_acc'].values)\n",
    "iso['category'] = 'alternative'\n",
    "iso.loc[iso['clone_acc'].isin(mane_select_clones), 'category'] = 'reference'\n",
    "iso.loc[iso['is_novel_isoform'], 'category'] = 'novel'\n",
    "\n",
    "# this df includes some stuff we filtered out - remove these\n",
    "iso = iso[iso[\"clone_acc\"].isin(clone_df[\"isoform\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iso['gene_symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_w_ref = list(iso[iso['category'] == 'reference']['gene_symbol'].unique())\n",
    "len(genes_w_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset iso df to only genes w MANE select isoform\n",
    "iso_sub = iso[iso['gene_symbol'].isin(genes_w_ref)]\n",
    "len(iso_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sub['valid_ppi_test'] = iso['clone_acc'].map(y2h.groupby('ad_clone_acc').apply(lambda rows: ((rows['Y2H_result'] == True) |\n",
    "                                                                                                 (rows['Y2H_result'] == False))\n",
    "                                                                                                 .any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sub['at_least_one_ppi'] = iso['clone_acc'].map(y2h.groupby('ad_clone_acc').apply(lambda rows: ((rows['Y2H_result'] == True))\n",
    "                                                                                                    .any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1h = y1h.drop_duplicates('clone_acc')\n",
    "iso_sub['at_least_one_pdi'] = iso_sub['clone_acc'].map(y1h.set_index('clone_acc')['any_true'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sub['at_least_two_fold_activation'] = iso_sub['clone_acc'].map(\n",
    "                                            m1h.set_index('clone_acc')['M1H_mean'].abs() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_sub.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = met_brewer.met_brew(name=\"Monet\")\n",
    "sns.palplot(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(w=2.1, h=1.5)\n",
    "cats = ['reference', 'alternative', 'novel']\n",
    "positives = []\n",
    "tested = []\n",
    "\n",
    "for cat in cats:\n",
    "    positives.append(iso_sub.loc[\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_one_pdi'].sum())\n",
    "    tested.append(iso_sub.loc[\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_one_pdi'].notnull().sum())\n",
    "    \n",
    "for cat in cats:\n",
    "    positives.append(iso_sub.loc[iso_sub['valid_ppi_test'] &\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_one_ppi'].sum())\n",
    "    tested.append(iso_sub.loc[iso_sub['valid_ppi_test'] &\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_one_ppi'].notnull().sum())\n",
    "\n",
    "for cat in cats:\n",
    "    positives.append(iso_sub.loc[\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_two_fold_activation'].sum())\n",
    "    tested.append(iso_sub.loc[\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_two_fold_activation'].notnull().sum())\n",
    "for cat in cats:\n",
    "    tested_iso = (iso_sub['valid_ppi_test'] & \n",
    "                    iso_sub['at_least_two_fold_activation'].notnull() &\n",
    "                    iso_sub['at_least_one_pdi'].notnull() &\n",
    "                    (iso_sub['category'] == cat))\n",
    "    positives.append((iso_sub.loc[tested_iso, 'at_least_one_ppi'] |\n",
    "                 iso_sub.loc[tested_iso, 'at_least_two_fold_activation'] |\n",
    "                 iso_sub.loc[tested_iso, 'at_least_one_pdi']).sum())\n",
    "    tested.append(tested_iso.sum())\n",
    "    \n",
    "vals = [p / n for p, n in zip(positives, tested)]\n",
    "#errs = [np.sqrt(((p / n) * (1 - (p / n)) / n)) for p, n in zip(positives, tested)]\n",
    "\n",
    "pos = np.array(positives)\n",
    "neg = np.array(tested) - pos\n",
    "fracs = np.array(vals)\n",
    "intv = stats.beta.interval(0.6827, pos + 1, neg + 1)\n",
    "errs = [fracs - intv[0], intv[1] - fracs]\n",
    "errs[0][pos == 0] = 0.\n",
    "errs[1][neg == 0] = 0.\n",
    "\n",
    "offset = 0.5\n",
    "x_pos = ([i for i in range(3)] + \n",
    "       [i + offset for i in range(3, 6)] + \n",
    "       [i + offset * 2 for i in range(6, 9)] +\n",
    "       [i + offset * 3 for i in range(9, 12)])\n",
    "\n",
    "\n",
    "ax.bar(x=x_pos, height=vals, color=[colors[0], colors[1], colors[2]] * 3)\n",
    "ax.errorbar(x=x_pos, y=vals, yerr=errs,\n",
    "            color='black',\n",
    "            fmt='none',\n",
    "            linewidth=1,\n",
    "            capsize=1)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_yticks(np.linspace(0, 1, 6))\n",
    "ax.set_yticks(np.linspace(0, 1, 11), minor=True)\n",
    "ax.set_yticklabels([f'{y:.0%}' for y in ax.get_yticks()])\n",
    "for loc in ['top', 'bottom', 'right']:\n",
    "    ax.spines[loc].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "ax.legend([Patch(facecolor=colors[i]) for i in range(3)],\n",
    "        ['Reference', 'Alternative', 'Novel'],\n",
    "        loc='upper left',\n",
    "        bbox_to_anchor=(1, 1),\n",
    "        frameon=False,\n",
    ")\n",
    "\n",
    "ax.set_xticks([x_pos[i] for i in [1, 4, 7, 10]])\n",
    "ax.set_xticklabels([\n",
    "   '≥ 1 PDI',\n",
    "   '≥ 1 PPI',\n",
    "   '≥ 2-fold\\nactivation/\\nrepression',\n",
    "   'Any one\\nof three',\n",
    "], \n",
    "                    ha='center',\n",
    "                    fontsize=6,\n",
    "                    )\n",
    "\n",
    "\n",
    "ax.set_ylabel('Percentage of isoforms')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "fig.savefig('../../figures/fig2/at-least-some-assay-result_ref-vs-alt-vs-novel_bar.pdf',\n",
    "            bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(w=2.5, h=1.75)\n",
    "cats = ['reference', 'alternative', 'novel']\n",
    "positives = []\n",
    "tested = []\n",
    "\n",
    "for cat in cats:\n",
    "    positives.append(iso_sub.loc[\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_one_pdi'].sum())\n",
    "\n",
    "for cat in cats:\n",
    "    positives.append(iso_sub.loc[iso_sub['valid_ppi_test'] &\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_one_ppi'].sum())\n",
    "\n",
    "for cat in cats:\n",
    "    positives.append(iso_sub.loc[\n",
    "                        (iso_sub['category'] == cat),\n",
    "                        'at_least_two_fold_activation'].sum())\n",
    "\n",
    "for cat in cats:\n",
    "    positives.append((iso_sub.loc[(iso_sub['category'] == cat), 'at_least_one_ppi'].fillna(False) |\n",
    "                      iso_sub.loc[(iso_sub['category'] == cat), 'at_least_two_fold_activation'].fillna(False) |\n",
    "                      iso_sub.loc[(iso_sub['category'] == cat), 'at_least_one_pdi'].fillna(False)).sum())    \n",
    "\n",
    "tested = [(iso_sub['category'] == cat).sum() for cat in cats] * 4\n",
    "vals = [p / n for p, n in zip(positives, tested)]\n",
    "\n",
    "pos = np.array(positives)\n",
    "neg = np.array(tested) - pos\n",
    "fracs = np.array(vals)\n",
    "intv = stats.beta.interval(0.6827, pos + 1, neg + 1)\n",
    "errs = [fracs - intv[0], intv[1] - fracs]\n",
    "errs[0][pos == 0] = 0.\n",
    "errs[1][neg == 0] = 0.\n",
    "\n",
    "offset = 0.5\n",
    "x_pos = ([i for i in range(3)] + \n",
    "       [i + offset for i in range(3, 6)] + \n",
    "       [i + offset * 2 for i in range(6, 9)] +\n",
    "       [i + offset * 3 for i in range(9, 12)])\n",
    "ax.bar(x=x_pos, height=vals, color=[colors[0], colors[1], colors[2]] * 3)\n",
    "ax.errorbar(x=x_pos, y=vals, yerr=errs,\n",
    "            color='black',\n",
    "            fmt='none',\n",
    "            capsize=2,\n",
    "            linewidth=1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_yticks(np.linspace(0, 1, 6))\n",
    "ax.set_yticks(np.linspace(0, 1, 11), minor=True)\n",
    "ax.set_yticklabels([f'{y:.0%}' for y in ax.get_yticks()])\n",
    "for loc in ['top', 'bottom', 'right']:\n",
    "    ax.spines[loc].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "ax.legend([Patch(facecolor=colors[i]) for i in range(3)],\n",
    "        ['Reference', 'Alternative', 'Novel'],\n",
    "        loc='upper left',\n",
    "        bbox_to_anchor=(1, 1),\n",
    "        frameon=False,\n",
    ")\n",
    "\n",
    "ax.set_ylabel('Percentage of isoforms')\n",
    "\n",
    "ax.set_xticks([x_pos[i] for i in [1, 4, 7, 10]])\n",
    "ax.set_xticklabels([\n",
    "   '≥ 1 PDI',\n",
    "   '≥ 1 PPI',\n",
    "   '≥ 2-fold\\nactivation/\\nrepression',\n",
    "   'Any one\\nof three',\n",
    "], \n",
    "                    ha='center',\n",
    "                    fontsize=6,\n",
    "                    )\n",
    "\n",
    "\n",
    "fig.savefig('../../figures/fig2/at-least-some-assay-result_ref-vs-alt-vs-novel_absolute_bar.pdf',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. make validation figures for Y2H (N2H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_n2h_ppi_validation_data()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_LIT = (60 / 255, 134 / 255, 184 / 255)\n",
    "COLOR_HURI = (155 / 255, 97 / 255, 153 / 255)\n",
    "colors = {'vignettes': 'yellow', \n",
    "          'isoform positives': COLOR_HURI,\n",
    "          'RRS - TF space specific': 'tab:red',\n",
    "          'Lit-BM - TF space specific': COLOR_LIT,\n",
    "          'isoform negatives': 'grey',\n",
    "          'RRS - from HuRI': 'tab:red',\n",
    "          'Lit-BM-13': COLOR_LIT,\n",
    "          'PRS - hPRS-v2': COLOR_LIT,\n",
    "          'RRS - hRRS-v2': 'tab:red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = ['PRS - hPRS-v2', \n",
    "           'RRS - hRRS-v2',\n",
    "           'isoform positives', \n",
    "           'isoform negatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart\n",
    "df['result'] = df['NLR'] > df.loc[df['source'] == 'RRS - hRRS-v2', 'NLR'].max()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.4, 1.5))\n",
    "validation_plot(data=df,\n",
    "                selections=[df['source'] == x for x in sources],\n",
    "                labels=[str(x) for x in sources],\n",
    "                colors=[colors[x] for x in sources],\n",
    "                result_column='result',\n",
    "                errorbar_capsize=0.175,\n",
    "                y_max=0.35,\n",
    "                xlabel_rotation=90,\n",
    "                bar_spacing=0.07,\n",
    "                draw_numbers=True,\n",
    "                fontsize=PAPER_FONTSIZE-1.5)\n",
    "#ax.set_xticklabels(sources, ha=\"right\", va=\"top\", rotation=30)\n",
    "rename_sources = {\n",
    "           'PRS - hPRS-v2': 'hPRS-v2', \n",
    "           'RRS - hRRS-v2': 'hRRS-v2',\n",
    "           'isoform positives': 'Isoform Positives', \n",
    "           'isoform negatives': 'Isoform Negatives',\n",
    "}\n",
    "ax.set_xticklabels([rename_sources[s] for s in sources])\n",
    "ax.set_yticklabels([f'{x:.0%}' for x in ax.get_yticks()])\n",
    "ax.set_title(\"PPI validation (mN2H assay)\")\n",
    "\n",
    "for loc in ['top', 'bottom', 'right']:\n",
    "    ax.spines[loc].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "ax.set_ylabel('Percentage positive')\n",
    "\n",
    "fig.savefig('../../figures/fig2/N2H_barplot.pdf', dpi=\"figure\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_styles = ['-', '-', '-', '-']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.3, 1.3))\n",
    "validation_titration_plot(data=df, \n",
    "                          selections=[df['source'] == x for x in sources],\n",
    "                          labels=[rename_sources[s] for s in sources],\n",
    "                          colors=[colors[x] for x in sources],\n",
    "                          line_styles=line_styles,\n",
    "                          score_column='log2 NLR',\n",
    "                          threshold=df.loc[df['source'] == 'RRS - hRRS-v2', 'log2 NLR'].max(),\n",
    "                          xmin=3,\n",
    "                          ax=ax)\n",
    "ax.set_xlabel('Log2 NLR threshold')\n",
    "ax.set_yticklabels([f'{x:.0%}' for x in ax.get_yticks()])\n",
    "\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "for loc in ['top', 'right']:\n",
    "    ax.spines[loc].set_visible(False)\n",
    "\n",
    "ax.set_title(\"PPI validation (mN2H assay)\")\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.set_ylabel('Percentage positive')\n",
    "\n",
    "fig.savefig('../../figures/fig2/TFv02_titration.pdf',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. make validation figures for Y1H (luciferase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_PDI_luciferase_validation_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In PDI validation experiment, tested:')\n",
    "print(df['gene_symbol'].nunique(), 'different TF genes')\n",
    "print(df['clone_acc'].nunique(), 'different TF isoforms')\n",
    "print(df['Bait'].nunique(), 'different baits')\n",
    "print(df.shape[0], 'total PDIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the interaction calls if needed\n",
    "new_calls = []\n",
    "for i, row in df.iterrows():\n",
    "    clone = row['clone_acc']\n",
    "    bait = row['Bait']\n",
    "    orig_y1h_call = row['Interaction?']\n",
    "    \n",
    "    try:\n",
    "        updated_y1h_call = y1h[y1h['clone_acc'] == clone][bait].iloc[0]\n",
    "    except:\n",
    "        print(\"not found: clone: %s | bait: %s | orig call: %s\" % (clone, bait, orig_y1h_call))\n",
    "        updated_y1h_call = np.nan\n",
    "    new_calls.append(updated_y1h_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"updated_y1h_call\"] = new_calls\n",
    "df.updated_y1h_call.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any updated calls that became NaN\n",
    "df_nn = df[~pd.isnull(df['updated_y1h_call'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In PDI validation experiment, tested (updated w new calls):')\n",
    "print(df_nn['gene_symbol'].nunique(), 'different TF genes')\n",
    "print(df_nn['clone_acc'].nunique(), 'different TF isoforms')\n",
    "print(df_nn['Bait'].nunique(), 'different baits')\n",
    "print(df_nn.shape[0], 'total PDIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Isoforms per gene:')\n",
    "df_nn.groupby(['gene_symbol'])['clone_acc'].nunique().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Baits per isoform:')\n",
    "df_nn.groupby(['clone_acc'])['Bait'].nunique().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(w=1.5, h=2.)\n",
    "sns.stripplot(data=df, x='updated_y1h_call', y='Log2(FC)', ax=ax, order=[True, False], \n",
    "              palette=sns.color_palette(\"Set2\"), zorder=1)\n",
    "sns.pointplot(data=df, x='updated_y1h_call', y='Log2(FC)', ax=ax, order=[True, False],\n",
    "              color='black')\n",
    "effectsize, pvalue = stats.ttest_ind(df.loc[df['Y1H_positive'], 'Log2(FC)'].values,\n",
    "                df.loc[~df['Y1H_positive'], 'Log2(FC)'].values)\n",
    "ax.text(x=0.5, y=4, s='P = {:.1}'.format(pvalue), ha='center')\n",
    "ax.set_xlabel('eY1H result')\n",
    "ax.set_xticklabels(['+', '-'])\n",
    "ax.set_ylabel('Luciferase mean log2(FC)')\n",
    "fig.savefig('../../figures/fig2/PDI-luciferase_validation_point-plot.pdf',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.updated_y1h_call.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Y1H_positive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titration plot of positive vs negative\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(w=1.2, h=1.2)\n",
    "validation_titration_plot(data=df_nn,\n",
    "                          selections=[df_nn['updated_y1h_call'], \n",
    "                                      ~df_nn['updated_y1h_call']],\n",
    "                          score_column='Log2(FC)',\n",
    "                          labels=['eY1H +', 'eY1H -'],\n",
    "                          colors=[COLOR_HURI, 'grey'],\n",
    "                          ax=ax)\n",
    "ax.set_xlabel('Threshold of luciferase\\nmean Log2(FC)')\n",
    "plt.legend(loc=2, frameon=False, bbox_to_anchor=(0.6, 1))\n",
    "\n",
    "for loc in ['top', 'right']:\n",
    "    ax.spines[loc].set_visible(False)\n",
    "\n",
    "ax.set_yticks(np.linspace(0, 1, 6))\n",
    "ax.set_yticks(np.linspace(0, 1, 11), minor=True)\n",
    "ax.set_yticklabels([f'{y:.0%}' for y in ax.get_yticks()])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel('Percentage positive')\n",
    "ax.axvline(x=1, color='grey', linestyle='--', lw=1)\n",
    "ax.set_xticks(range(-2, 7), minor=True)\n",
    "ax.set_title(\"PDI Validation (Luciferase)\")\n",
    "    \n",
    "fig.savefig('../../figures/fig2/PDI-luciferase_validation_titration-plot.pdf',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(row):\n",
    "    a = row[['Replicate1', 'Replicate2', 'Replicate3']].values\n",
    "    b = row['Average (empty-pEZY3-VP160)']\n",
    "    \n",
    "    # this code doesn't work on kaia's env; need to update scipy which requires updating to py3.7\n",
    "    #pval = stats.ttest_1samp(list(a), b, alternative='greater').pvalue\n",
    "    \n",
    "    # return two-sided pval * 2 for now\n",
    "    pval = stats.ttest_1samp(list(a), b).pvalue * 2\n",
    "    \n",
    "    return pval\n",
    "\n",
    "df['p-value'] = df.apply(p_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive'] = (df['p-value'] < 0.05) & (df['Log2(FC)'] >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Interaction?')['positive'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(w=0.75, h=1.5)\n",
    "validation_plot(data=df,\n",
    "                selections=[df['Y1H_positive'], \n",
    "                           ~df['Y1H_positive']],\n",
    "                result_column='positive',\n",
    "                labels=['+', '-'],\n",
    "                colors=[COLOR_HURI, 'grey'],\n",
    "                errorbar_capsize=0.25,\n",
    "                ax=ax,\n",
    "                fontsize=PAPER_FONTSIZE-1)\n",
    "ax.set_ylim(0, 0.7)\n",
    "ax.set_xlabel('eY1H result')\n",
    "ax.set_ylabel('Fraction positive\\nin luciferase assay')\n",
    "\n",
    "ax.set_title(\"PDI Validation (Luciferase)\")\n",
    "\n",
    "for loc in ['top', 'bottom', 'right']:\n",
    "    ax.spines[loc].set_visible(False)\n",
    "    \n",
    "fig.savefig('../../figures/fig2/Luciferase_barplot.pdf', bbox_inches='tight', dpi='figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. make reproducibility figure for M1H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, \n",
    "                        nrows=1, \n",
    "                        sharey=True)\n",
    "fig.set_size_inches(w=4, h=1.5)\n",
    "m1h_min = m1h[['M1H_rep1', 'M1H_rep2', 'M1H_rep3']].min().min()\n",
    "m1h_max = m1h[['M1H_rep1', 'M1H_rep2', 'M1H_rep3']].max().max()\n",
    "m1h_min = -3\n",
    "m1h_max = 12\n",
    "\n",
    "for i, (a, b) in enumerate([('1', '2'), ('1', '3'), ('2', '3')]):\n",
    "    axs[i].scatter(x=m1h[f'M1H_rep{a}'].values,\n",
    "            y=m1h[f'M1H_rep{b}'].values,\n",
    "                alpha=0.8,\n",
    "                s=0.6,\n",
    "                linewidth=0,\n",
    "            )\n",
    "    r = stats.pearsonr(m1h[f'M1H_rep{a}'].values, m1h[f'M1H_rep{b}'].values)[0]\n",
    "    axs[i].text(s=f\"R² = {r**2:.3f}\",\n",
    "                x=4, \n",
    "                y=1)\n",
    "    axs[i].set_xlabel(f'Replicate {a}')\n",
    "    axs[i].set_ylabel(f'Replicate {b}')\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim(m1h_min, m1h_max)\n",
    "    ax.set_xlim(m1h_min, m1h_max)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_yticks(range(0, 13, 4))\n",
    "    ax.set_yticks(range(-2, 13, 2), minor=True)\n",
    "    ax.set_xticks(range(0, 13, 4))\n",
    "    ax.set_xticks(range(-2, 13, 2), minor=True)\n",
    "\n",
    "# same ticks\n",
    "axs[1].set_title('M1H log2(activation fold change) across replicates')\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "fig.savefig(\"../../figures/fig2/M1H_replicate_scatter.pdf\", \n",
    "            bbox_inches=\"tight\", \n",
    "            dpi=\"figure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. make tables needed for cytoscape network fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # table of edges\n",
    "# #    - clone to (edge + clone_id) + to duplicate\n",
    "# # table of nodes\n",
    "# #    - clone to gene\n",
    "# #    - dna vs isoform vs \n",
    "\n",
    "# ppi = load_full_y2h_data_including_controls()\n",
    "# ppi = ppi.loc[(ppi['category'] == 'tf_isoform_ppis') &\n",
    "#               (ppi['Y2H_result'] == True),\n",
    "#               ['ad_clone_acc', 'ad_gene_symbol', 'db_gene_symbol']]\n",
    "# ppi = ppi.rename(columns={'ad_clone_acc': 'isoform',\n",
    "#                           'db_gene_symbol': 'partner'})\n",
    "# ppi['partner'] = ppi['partner'] + '-' + ppi['ad_gene_symbol']\n",
    "# pdi = pd.read_csv('../../data/internal/a2_juan_pdi_w_unique_isoacc.tsv', sep='\\t')\n",
    "# clones = load_valid_isoform_clones()\n",
    "# pdi = pdi.loc[pdi['unique_acc'].isin(clones['clone_acc']), :]\n",
    "# pdi['partner'] = pdi['bait'] + '-' + pdi['tf']\n",
    "# pdi['isoform'] = pdi['unique_acc']\n",
    "# edges = pd.concat([ppi.loc[:, ['isoform', 'partner']],\n",
    "#                    pdi.loc[:, ['isoform', 'partner']]])\n",
    "# edges.to_csv('../../output/edges.tsv', sep='\\t', index=False)\n",
    "\n",
    "# clones = clones.rename(columns={'clone_acc': 'node_id'})\n",
    "# clones['type'] = 'isoform'\n",
    "# dna = pd.DataFrame(data=pdi['partner'].unique(), columns=['node_id'])\n",
    "# dna['type'] = 'DNA'\n",
    "# proteins = pd.DataFrame(data=ppi['partner'].unique(), columns=['node_id'])\n",
    "# proteins['type'] = 'Protein'\n",
    "# nodes = pd.concat([clones, proteins, dna], sort=True)\n",
    "# nodes.to_csv('../../output/node_table.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. make example expression plot for ZNF414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developmental_tissue_expression_plot(gene_name, figsize, ylim, means, cols, fig_suffix):\n",
    "    locs = [x for x in list(means.index) if x.split(\"|\")[0] == gene_name]\n",
    "    \n",
    "    # include isos that aren't cloned\n",
    "    locs = list(set(locs + [x for x in list(means.index) if x.split(\" \")[1][:-4] == gene_name]))\n",
    "    \n",
    "    n_isos = len(means.loc[locs])\n",
    "    palette = met_brewer.met_brew(name=\"Egypt\")\n",
    "    fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "    fig.set_size_inches(figsize)\n",
    "    ### bar chart ###\n",
    "    (means.loc[locs, cols]\n",
    "          .T\n",
    "          .plot.bar(ax=axes[0],\n",
    "                    legend=False,\n",
    "                    width=0.7,\n",
    "                    color=list(palette)))\n",
    "    ### percentages ###\n",
    "    raw_means = 2 ** means.loc[locs, cols] - 1.\n",
    "    (raw_means.div(raw_means.sum(axis=0))\n",
    "              .T.plot.bar(ax=axes[1], \n",
    "                          stacked=True,\n",
    "                          legend=False,\n",
    "                          color=list(palette)))\n",
    "    axes[0].set_ylabel('log2(TPM + 1)\\n')\n",
    "    axes[0].set_ylim(ylim)\n",
    "    axes[1].set_ylabel('Percentage of\\ngene expression')\n",
    "    axes[1].set_yticklabels(['{:.0%}'.format(t) for t in axes[1].get_yticks()])\n",
    "    axes[1].legend(loc='lower left', bbox_to_anchor=(1, 0), frameon=False)\n",
    "    axes[0].axhline(y=1, color='black', linewidth=0.5, linestyle=\"dashed\")\n",
    "    \n",
    "    axes[0].spines['top'].set_visible(False)\n",
    "    axes[1].spines['top'].set_visible(False)\n",
    "    axes[0].spines['right'].set_visible(False)\n",
    "    axes[1].spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.25)\n",
    "    plt.savefig('../../figures/fig2/expression_' + gene_name + '_' + fig_suffix + '.pdf',\n",
    "                bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notestis_cols = [x for x in means_dev.columns if \"testis\" not in x]\n",
    "notestis_cols = [x for x in notestis_cols if \"median\" not in x]\n",
    "notestis_cols = [x for x in notestis_cols if \"max\" not in x]\n",
    "notestis_cols = [x for x in notestis_cols if \"ovary\" not in x]\n",
    "notestis_cols = [x for x in notestis_cols if \"brain\" not in x]\n",
    "developmental_tissue_expression_plot(\"ZNF414\", (7.2, 1.75), (0, 6), means_dev, notestis_cols, \n",
    "                                     \"means_dev_notestis_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_cols = [x for x in means_dev.columns if \"liver\" in x]\n",
    "developmental_tissue_expression_plot(\"ZNF414\", (3, 1.75), (0, 6), means_dev, liver_cols, \n",
    "                                     \"means_dev_liver_large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. make alphafold disorder plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dssp_dir = Path('../../data/processed/dssp_alphafold')\n",
    "# dfs = []\n",
    "# for dssp_file_path in dssp_dir.iterdir():\n",
    "#     dssp = make_dssp_dict(dssp_file_path)\n",
    "#     dfs.append(pd.DataFrame(data=[(dssp_file_path.stem, k[1][1], v[0], v[1], v[2]) for k, v in dssp[0].items()],\n",
    "#                       columns=['clone_name', 'position', 'aa', 'secondary_structure', 'ASA']))\n",
    "# df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "# # NOTE: the Davey analysis uses GGXGG whereas I think this paper is GXG\n",
    "# # Wilke: Tien et al. 2013 https://doi.org/10.1371/journal.pone.0080635\n",
    "# max_asa = {\n",
    "#         \"ALA\": 129.0,\n",
    "#         \"ARG\": 274.0,\n",
    "#         \"ASN\": 195.0,\n",
    "#         \"ASP\": 193.0,\n",
    "#         \"CYS\": 167.0,\n",
    "#         \"GLN\": 225.0,\n",
    "#         \"GLU\": 223.0,\n",
    "#         \"GLY\": 104.0,\n",
    "#         \"HIS\": 224.0,\n",
    "#         \"ILE\": 197.0,\n",
    "#         \"LEU\": 201.0,\n",
    "#         \"LYS\": 236.0,\n",
    "#         \"MET\": 224.0,\n",
    "#         \"PHE\": 240.0,\n",
    "#         \"PRO\": 159.0,\n",
    "#         \"SER\": 155.0,\n",
    "#         \"THR\": 172.0,\n",
    "#         \"TRP\": 285.0,\n",
    "#         \"TYR\": 263.0,\n",
    "#         \"VAL\": 174.0,\n",
    "#     }\n",
    "# max_asa = {protein_letters_3to1[k.capitalize()]: v for k, v in max_asa.items()}\n",
    "# df['RSA'] = df['ASA'] / df['aa'].map(max_asa)\n",
    "# df['RSA'] = df['RSA'].clip(upper=1.)\n",
    "# WINDOW_SIZE_RESIDUES = 20\n",
    "# DISORDER_WINDOW_RSA_CUTOFF = 0.5\n",
    "# rsa_window_col = f'RSA_window_{WINDOW_SIZE_RESIDUES}'\n",
    "# df[rsa_window_col] = (\n",
    "#          df.groupby('clone_name')['RSA']\n",
    "#            .rolling(window=WINDOW_SIZE_RESIDUES * 2 + 1,\n",
    "#                   min_periods=WINDOW_SIZE_RESIDUES + 1,\n",
    "#                   center=True)\n",
    "#              .mean().rename(rsa_window_col).droplevel('clone_name')\n",
    "# )\n",
    "# df['is_disordered'] = df[rsa_window_col] >= DISORDER_WINDOW_RSA_CUTOFF\n",
    "\n",
    "# # correct for long helices which are structured, usually bound to a partner\n",
    "# # but have high RSA in the monomer state\n",
    "# DISORDER_HELIX_LENGTH_CUTOFF = 20\n",
    "# to_change = []\n",
    "# for clone_name, df_clone in df.groupby('clone_name'):\n",
    "#     helix_count = 0\n",
    "#     for _i, row in df_clone.iterrows():\n",
    "#         if row['secondary_structure'] == 'H':\n",
    "#             helix_count += 1\n",
    "#         else:\n",
    "#             if helix_count >= DISORDER_HELIX_LENGTH_CUTOFF:\n",
    "#                 for i in range(row['position'] - 1, row['position'] - helix_count, -1):\n",
    "#                     to_change.append((clone_name, i))\n",
    "#             helix_count = 0\n",
    "#     if helix_count >= DISORDER_HELIX_LENGTH_CUTOFF:\n",
    "#         for i in range(row['position'], row['position'] - helix_count, -1):\n",
    "#             to_change.append((clone_name, i))\n",
    "# to_change = (df['clone_name'] + '_' + df['position'].astype(str)).isin({a + '_' + str(b) for a, b in to_change})\n",
    "# print(f'{to_change.sum()} ({to_change.mean():.0%}) aa in helices of length 20 aa or more')\n",
    "# print(f\"{df.loc[to_change, 'is_disordered'].mean():.0%} of residues in long helices misclassified as disordered\")\n",
    "# df.loc[to_change, 'is_disordered'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = load_annotated_TFiso1_collection()\n",
    "len(tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['is_cloned_reference'] = df['clone_name'].map({iso.name: iso.name == tf.cloned_reference_isoform.name\n",
    "#                                                   for tf in tfs.values() \n",
    "#                                                   for iso in tf.cloned_isoforms})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nonan = df.loc[~pd.isnull(df['is_cloned_reference'])]\n",
    "# f_dis_ref = df_nonan[df_nonan['is_cloned_reference'] == True].groupby('clone_name')['is_disordered'].mean()\n",
    "# f_dis_alt = df_nonan[df_nonan['is_cloned_reference'] == False].groupby('clone_name')['is_disordered'].mean()\n",
    "\n",
    "# # randomization p-value\n",
    "# obs_val = f_dis_alt.median() - f_dis_ref.median()\n",
    "\n",
    "# print(\"MEDIAN NUM OF RESIDUES IN DISORDERED REGIONS IN ALT ISOS: %s\" % (f_dis_alt.median()*100))\n",
    "# print(\"MEDIAN NUM OF RESIDUES IN DISORDERED REGIONS IN REF ISOS: %s\" % (f_dis_ref.median()*100))\n",
    "# rnd_vals = []\n",
    "# gene_to_isoforms = {tf.name: [iso.name for iso in tf.cloned_isoforms] for tf in tfs.values()}\n",
    "# np.random.seed(34298793)\n",
    "# for _i in tqdm.tqdm(range(1, 10000)):\n",
    "#     all_vals = df.groupby('clone_name')['is_disordered'].mean()\n",
    "#     rnd_refs = set()\n",
    "#     for isoforms in gene_to_isoforms.values():\n",
    "#         rnd_refs.add(np.random.choice(isoforms))\n",
    "#     rnd_vals.append(all_vals.loc[~all_vals.index.isin(rnd_refs)].median()\n",
    "#                     -\n",
    "#                     all_vals.loc[all_vals.index.isin(rnd_refs)].median())\n",
    "# pval = sum(rnd_val >= obs_val for rnd_val in rnd_vals) / len(rnd_vals) * 2\n",
    "# print(f'p = {pval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1)\n",
    "# fig.set_size_inches(w=1.1, h=1.8)\n",
    "# data = (df.groupby(['clone_name', 'is_cloned_reference'])\n",
    "#                             ['is_disordered']\n",
    "#                             .mean()\n",
    "#                             .reset_index())\n",
    "# # need to fix the violinplot_reflected function!\n",
    "# violinplot_reflected(data=data,\n",
    "#                      x='is_cloned_reference',\n",
    "#                      y='is_disordered',\n",
    "#                      order=[True, False],\n",
    "#                      cut=0,\n",
    "#                      color=sns.color_palette(\"Set2\")[0],\n",
    "#                      )\n",
    "# ax.set_ylim(0, 1)\n",
    "# ax.set_xlim(-0.5, 1.5)\n",
    "# ax.set_ylabel('Residues in disordered regions')\n",
    "# ax.set_yticks(np.linspace(0, 1, 6))\n",
    "# ax.set_yticks(np.linspace(0, 1, 11), minor=True)\n",
    "# ax.set_yticklabels([f'{y:.0%}' for y in ax.get_yticks()])\n",
    "# ax.set_xlabel('')\n",
    "# ax.set_xticklabels(['Reference\\nisoforms', 'Alternative\\nisoforms'])\n",
    "# for loc in ['top', 'right', 'bottom']:\n",
    "#     ax.spines[loc].set_visible(False)\n",
    "# ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "# annotate_pval(ax, 0, 1, 1.05, 0, 1.05, pval, PAPER_FONTSIZE - 1)\n",
    "\n",
    "# # manually set left axis so it stops at 1.0\n",
    "# ax.set_ylim((-0.1, 1.1))\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "# axes_to_data = ax.transAxes + ax.transData.inverted()\n",
    "# left_spine_in_data_coords = axes_to_data.transform((0, 0))\n",
    "# ax.plot([left_spine_in_data_coords[0], left_spine_in_data_coords[0]], [0, 1],\n",
    "#          color=ax.spines['bottom'].get_edgecolor(), linewidth=ax.spines['bottom'].get_linewidth())\n",
    "# ax.tick_params(axis='x', which='major', pad=-5)\n",
    "\n",
    "# fig.savefig('../../figures/fig2/disordered-residued-pct-per-isoform_TFiso1_violin.pdf',\n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. additional summary fig -- gain vs. loss of function in each assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import load_ref_vs_alt_isoforms_table\n",
    "\n",
    "# easiest to do this w the ref/alt table\n",
    "pairs = load_ref_vs_alt_isoforms_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a gain, loss, or similar function in each experiment\n",
    "def pdi_status(row):\n",
    "    if row.n_positive_PDI_ref_filtered > 0:\n",
    "        if row.n_positive_PDI_alt_filtered == 0:\n",
    "            return \"loss\"\n",
    "        elif row.n_shared_PDI == row.n_PDI_successfully_tested_in_ref_and_alt:\n",
    "            return \"no change\"\n",
    "        elif pd.isnull(row.n_positive_PDI_alt_filtered):\n",
    "            return \"NA\"\n",
    "        else:\n",
    "            return \"change\"\n",
    "    elif row.n_positive_PDI_ref_filtered == 0:\n",
    "        if row.n_positive_PDI_alt_filtered > 0:\n",
    "            return \"gain\"\n",
    "        else:\n",
    "            return \"NA\"\n",
    "    else:\n",
    "        return \"NA\"\n",
    "    \n",
    "pairs[\"PDI_category\"] = pairs.apply(pdi_status, axis=1)\n",
    "pairs[\"PDI_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a gain, loss, or similar function in each experiment\n",
    "def ppi_status(row):\n",
    "    if row.n_positive_PPI_ref_filtered > 0:\n",
    "        if row.n_positive_PPI_alt_filtered == 0:\n",
    "            return \"loss\"\n",
    "        elif row.n_shared_PPI == row.n_PPI_successfully_tested_in_ref_and_alt:\n",
    "            return \"no change\"\n",
    "        elif pd.isnull(row.n_positive_PPI_alt_filtered):\n",
    "            return \"NA\"\n",
    "        else:\n",
    "            return \"change\"\n",
    "    elif row.n_positive_PPI_ref_filtered == 0:\n",
    "        if row.n_positive_PPI_alt_filtered > 0:\n",
    "            return \"gain\"\n",
    "        else:\n",
    "            return \"NA\"\n",
    "    else:\n",
    "        return \"NA\"\n",
    "    \n",
    "pairs[\"PPI_category\"] = pairs.apply(ppi_status, axis=1)\n",
    "pairs[\"PPI_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1h_status(row):\n",
    "    \n",
    "    # ref is activator\n",
    "    if row.activation_ref >= 1:\n",
    "        if row.activation_fold_change_log2 <= -1 and row.activation_alt <= 1 and row.activation_alt >= -1:\n",
    "            return \"loss\"\n",
    "        elif not pd.isnull(row.activation_fold_change_log2):\n",
    "            \n",
    "            # only consider iso to be rewired if foldchange > 2x\n",
    "            if np.abs(row.activation_fold_change_log2) >= 1:\n",
    "                return \"change\"\n",
    "            else:\n",
    "                return \"no change\"\n",
    "\n",
    "        else:\n",
    "            return \"NA\"\n",
    "    \n",
    "    # ref is repressor\n",
    "    elif row.activation_ref <= -1:\n",
    "        if row.activation_fold_change_log2 >= 1 and row.activation_alt <= 1 and row.activation_alt >= -1:\n",
    "            return \"loss\"\n",
    "        elif not pd.isnull(row.activation_fold_change_log2):\n",
    "            \n",
    "            # only consider iso to be rewired if foldchange > 2x\n",
    "            if np.abs(row.activation_fold_change_log2) >= 1:\n",
    "                return \"change\"\n",
    "            else:\n",
    "                return \"no change\"\n",
    "        else:\n",
    "            return \"NA\"\n",
    "        \n",
    "    # no ref data so can't make conclusions\n",
    "    elif pd.isnull(row.activation_ref):\n",
    "        return \"NA\"\n",
    "    \n",
    "    # ref is middling so can be GoF\n",
    "    else:\n",
    "        if row.activation_fold_change_log2 >= 1:\n",
    "            return \"gain\"\n",
    "        elif row.activation_fold_change_log2 <= -1:\n",
    "            return \"gain\"\n",
    "        \n",
    "        # if both isoforms are middling, consider similar\n",
    "        elif not pd.isnull(row.activation_fold_change_log2):\n",
    "            return \"no change\"\n",
    "        \n",
    "        else:\n",
    "            return \"NA\"\n",
    "\n",
    "pairs[\"M1H_category\"] = pairs.apply(m1h_status, axis=1)\n",
    "pairs[\"M1H_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi = pd.DataFrame(pairs[\"PPI_category\"].value_counts())\n",
    "pdi = pd.DataFrame(pairs[\"PDI_category\"].value_counts())\n",
    "m1h = pd.DataFrame(pairs[\"M1H_category\"].value_counts())\n",
    "\n",
    "tots = ppi.join(pdi, lsuffix=\"_PPI\", rsuffix=\"_PDI\")\n",
    "tots = tots.join(m1h)\n",
    "tots.columns = ['PPI', 'PDI', 'M1H']\n",
    "\n",
    "tots_nonan = tots.loc[[\"no change\", \"loss\", \"change\", \"gain\"]]\n",
    "perc_nonan = tots_nonan/tots_nonan.sum(axis=0)\n",
    "perc_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = met_brewer.met_brew(name=\"Hokusai1\")\n",
    "colors.append(\"lightgrey\")\n",
    "colors = colors[::-1]\n",
    "sns.palplot(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(0.75, 1.5))\n",
    "\n",
    "xs = [\"PPIs\", \"PDIs\", \"transcriptional\\nactivity\"]\n",
    "y1 = list(perc_nonan.loc[\"no change\"])\n",
    "y2 = list(perc_nonan.loc[\"loss\"])\n",
    "b2 = np.add(y1, y2)\n",
    "y3 = list(perc_nonan.loc[\"change\"])\n",
    "b3 = np.add(b2, y3)\n",
    "y4 = list(perc_nonan.loc[\"gain\"])\n",
    "\n",
    "ax.bar(xs, y1, color=colors[0], label=\"no change\", edgecolor=\"black\", linewidth=0.5)\n",
    "ax.bar(xs, y2, bottom=y1, color=colors[1], label=\"loss of function\", edgecolor=\"black\", linewidth=0.5)\n",
    "ax.bar(xs, y3, bottom=b2, color=colors[3], label=\"change of function\", edgecolor=\"black\", linewidth=0.5)\n",
    "ax.bar(xs, y4, bottom=b3, color=colors[4], label=\"gain of function\", edgecolor=\"black\", linewidth=0.5)\n",
    "\n",
    "# add legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='upper left', bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "ax.set_ylabel(\"Percentage of\\nalternative isoforms\")\n",
    "ax.set_xticklabels(xs, rotation=30, rotation_mode='anchor', ha='right', va='top')\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "ax.set_yticklabels([\"%s%%\" % x for x in [0, 20, 40, 60, 80, 100]])\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "#ax.spines['bottom'].set_visible(False)\n",
    "#ax.xaxis.set_tick_params(length=0)\n",
    "fig.savefig(\"../../figures/fig2/Assay_Summary.GainLossChange.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. check riboseq overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riboseq_f = \"../../data/processed/ribo_seq/counts.RiboSeq.txt\"\n",
    "riboseq = pd.read_table(riboseq_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riboseq_samps = [x for x in riboseq.columns if x.startswith(\"SRR\")]\n",
    "len(riboseq_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riboseq[\"max\"] = riboseq[riboseq_samps].max(axis=1)\n",
    "riboseq[\"mean\"] = riboseq[riboseq_samps].mean(axis=1)\n",
    "riboseq[\"median\"] = riboseq[riboseq_samps].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riboseq[\"chrom\"] = riboseq[\"AltAnalyze_ID\"].str.extract(r'(chr[0-9]{1,2}|X|Y|MT):')\n",
    "riboseq[\"jx_start\"] = riboseq[\"AltAnalyze_ID\"].str.extract(r'chr(?:[0-9]{1,2}|X|Y|MT):(\\d+)').astype(int)\n",
    "riboseq[\"jx_end\"] = riboseq[\"AltAnalyze_ID\"].str.extract(r'-(\\d+)$').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get unique junctions across all isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def flatten_set_list(list_of_sets):\n",
    "    return list(chain.from_iterable(list_of_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify all junctions in tfiso1.0 collection by the number of isoforms they are present in\n",
    "junc_dict = {}\n",
    "idx = 0\n",
    "\n",
    "for tf in clone_tfs.keys():\n",
    "    \n",
    "    ref = clone_tfs[tf].reference_isoform.name\n",
    "    iso_juncs_dict = {}\n",
    "    \n",
    "    for iso in clone_tfs[tf].isoforms:\n",
    "        \n",
    "        iso_juncs = set()\n",
    "        \n",
    "        for i in range(len(iso.exons) - 1):\n",
    "            \n",
    "            if iso.strand == \"+\":\n",
    "                iso_juncs.add((iso.exons[i].end, iso.exons[i+1].start+1))\n",
    "            if iso.strand == \"-\":\n",
    "                iso_juncs.add((iso.exons[i].start+1, iso.exons[i+1].end))\n",
    "        \n",
    "        iso_juncs_dict[iso.name] = iso_juncs\n",
    "    \n",
    "    # then re-loop\n",
    "    for iso in clone_tfs[tf].isoforms:\n",
    "        iso_juncs = iso_juncs_dict[iso.name]\n",
    "        other_isos = [x for x in iso_juncs_dict.keys() if x != iso.name]\n",
    "        other_juncs = [iso_juncs_dict[x] for x in other_isos]\n",
    "        other_juncs = set(flatten_set_list(other_juncs))\n",
    "        uniq_juncs = iso_juncs.difference(other_juncs)\n",
    "        if len(uniq_juncs) > 0:\n",
    "            \n",
    "            # define iso category\n",
    "            if iso.name == ref:\n",
    "                iso_category = \"ref\"\n",
    "            elif hasattr(iso, 'is_novel_isoform') and iso.is_novel_isoform():\n",
    "                iso_category = \"novel\"\n",
    "            else:\n",
    "                iso_category = \"alt\"\n",
    "                \n",
    "            # define iso cloned status\n",
    "            if hasattr(iso, 'clone_acc'):\n",
    "                iso_cloned = \"cloned\"\n",
    "                clone_acc = iso.clone_acc\n",
    "            else:\n",
    "                iso_cloned = \"uncloned\"\n",
    "                clone_acc = np.nan\n",
    "            \n",
    "                \n",
    "            for junc in uniq_juncs:\n",
    "                junc_dict[idx] = {\"iso_name\": iso.name,\n",
    "                                  \"iso_category\": iso_category,\n",
    "                                  \"iso_cloned\": iso_cloned,\n",
    "                                  \"clone_acc\": clone_acc,\n",
    "                                  \"chrom\": clone_tfs[tf].chrom,\n",
    "                                  \"jx_start\": junc[0],\n",
    "                                  \"jx_end\": junc[1],\n",
    "                                  \"strand\": iso.strand}\n",
    "                idx += 1\n",
    "            \n",
    "                \n",
    "        \n",
    "        \n",
    "uniq_junc_df = pd.DataFrame.from_dict(junc_dict, orient=\"index\")\n",
    "uniq_junc_df.iso_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "riboseq_mrg_uniq = uniq_junc_df.merge(riboseq[riboseq['max'] >= 5], on=['chrom', 'jx_start', 'jx_end'])\n",
    "len(riboseq_mrg_uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riboseq_mrg_uniq.iso_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_junc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tots = pd.DataFrame(uniq_junc_df[[\"iso_name\", \"iso_category\"]].drop_duplicates().iso_category.value_counts())\n",
    "present = pd.DataFrame(riboseq_mrg_uniq[[\"iso_name\", \"iso_category\"]].drop_duplicates().iso_category.value_counts())\n",
    "perc = tots.join(present, lsuffix='_tot', rsuffix='_present')\n",
    "perc['percent'] = (perc['count_present']/perc['count_tot'])*100\n",
    "perc.loc[[\"ref\", \"alt\", \"novel\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = met_brewer.met_brew(name=\"VanGogh2\")\n",
    "palette={\"ref\": colors[2],\n",
    "         \"novel\": colors[7],\n",
    "         \"alt\": colors[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = perc.reset_index()\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(0.75, 1.75))\n",
    "ax = sns.barplot(data=perc, x=\"iso_category\", y=\"percent\",\n",
    "                 order=[\"ref\", \"alt\", \"novel\"], palette=palette)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Percent of isoforms with unique\\njunctions present in RiboSeq data\")\n",
    "\n",
    "perc[\"iso_category\"] = pd.Categorical(perc[\"iso_category\"], categories=[\"ref\", \"alt\", \"novel\"], ordered=True)\n",
    "sorted_perc = perc.sort_values(by=[\"iso_category\"])\n",
    "\n",
    "for bar, (_, row) in zip(ax.patches, sorted_perc.iterrows()):\n",
    "    # Percentage value along the top of each bar\n",
    "    percent = f\"{row['percent']:.0f}%\"  # Format percentage\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        bar.get_height() + 0.5,  # Slightly above the bar\n",
    "        percent, \n",
    "        ha=\"center\", va=\"bottom\", fontsize=PAPER_FONTSIZE-2\n",
    "    )\n",
    "    \n",
    "    # n value along the bottom of each bar\n",
    "    n_value = row[\"count_tot\"]  # Format n-value\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        0,  # bottom of bar\n",
    "        n_value, \n",
    "        color=\"white\",\n",
    "        ha=\"center\", va=\"bottom\", fontsize=PAPER_FONTSIZE-2\n",
    "    )\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "ax.set_yticks((0, 20, 40, 60, 80, 100))\n",
    "ax.set_yticklabels([\"%s%%\" % y for y in ax.get_yticks()])\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/RiboSeq_ExpressionQCut_Total.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tots = uniq_junc_df[[\"iso_name\", \n",
    "                     \"iso_cloned\", \n",
    "                     \"iso_category\"]].drop_duplicates().groupby([\"iso_category\", \n",
    "                                                                 \"iso_cloned\"])[\"iso_name\"].agg(\"count\").reset_index()\n",
    "present = riboseq_mrg_uniq[[\"iso_name\", \n",
    "                     \"iso_cloned\", \n",
    "                     \"iso_category\"]].drop_duplicates().groupby([\"iso_category\", \"iso_cloned\"])[\"iso_name\"].agg(\"count\").reset_index()\n",
    "perc_all = tots.merge(present, on=[\"iso_category\", \"iso_cloned\"], how=\"left\", suffixes=(\"_tot\", \"_present\"))\n",
    "perc_all[\"percent\"] = (perc_all[\"iso_name_present\"]/perc_all[\"iso_name_tot\"])*100\n",
    "perc_all.sort_values(by=\"percent\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riboseq_mrg_uniq[riboseq_mrg_uniq['iso_category'] == 'novel'][['iso_name', 'chrom', 'jx_start',\n",
    "                                                               'jx_end', 'AltAnalyze_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and subset by max expression\n",
    "mm[\"max_dev_qcut\"] = pd.qcut(mm[\"max_dev\"], q=4, labels=list(range(1, 5)))\n",
    "mm[\"max_gtex_ds_qcut\"] = pd.qcut(mm[\"max_gtex_ds\"], q=4, labels=list(range(1, 5)))\n",
    "mm[\"med_dev_qcut\"] = pd.qcut(mm[\"median_dev\"], q=4, labels=list(range(1, 5)))\n",
    "mm[\"med_gtex_ds_qcut\"] = pd.qcut(mm[\"median_gtex_ds\"], q=4, labels=list(range(1, 5)))\n",
    "\n",
    "def extract_name(row, col):\n",
    "    if \"noclone\" in row[col]:\n",
    "        iso_name = row[col].split(\" \")[1].split(\"_\")[0]\n",
    "    else:\n",
    "        clone_acc = row[col].split(\" \")[0]\n",
    "        iso_name = clone_acc.split(\"|\")[0] + \"-\" + clone_acc.split(\"|\")[1].split(\"/\")[0]\n",
    "    return iso_name\n",
    "\n",
    "mm[\"iso_name\"] = mm.apply(extract_name, axis=1, col=\"UID_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_map[\"iso_name\"] = status_map.apply(extract_name, axis=1, col=\"clone_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_map.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = mm.merge(status_map[[\"iso_name\", \"status\"]], on=\"iso_name\")\n",
    "len(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now, iterate through the bins and calculate percent of isoforms that show junction-level translation\n",
    "qcut_percs = pd.DataFrame()\n",
    "\n",
    "for col in [\"max_dev\", \"max_gtex_ds\", \"med_dev\", \"med_gtex_ds\"]:\n",
    "    col_qcut = \"%s_qcut\" % col\n",
    "    \n",
    "    for qcut in range(1, 5):\n",
    "        print(\"QUARTILE: %s\" % (qcut))\n",
    "\n",
    "        mm_sub = mm[mm[col_qcut] == qcut]\n",
    "        print(\"num isos in qcut: %s\" % len(mm_sub))\n",
    "\n",
    "        mm_sub_w_jx = mm_sub.merge(uniq_junc_df[[\"iso_name\", \"chrom\", \"jx_start\", \"jx_end\"]], \n",
    "                                   on=[\"iso_name\"])\n",
    "        print(\"num unique junctions in qcut: %s\" % len(mm_sub_w_jx))\n",
    "        \n",
    "        # filter for riboseq junctions with at least 5 reads\n",
    "        ribo_seq_sub_w_jx = mm_sub_w_jx.merge(riboseq[riboseq['max'] >= 5][[\"chrom\", \"jx_start\", \"jx_end\",\n",
    "                                                                            \"max\", \"median\"]],\n",
    "                                              on=[\"chrom\", \"jx_start\", \"jx_end\"])\n",
    "        print(\"num junctions in riboseq: %s\" % len(ribo_seq_sub_w_jx))\n",
    "\n",
    "\n",
    "        tots = mm_sub_w_jx[[\"iso_name\", \"status\"]].drop_duplicates().groupby([\"status\"])[\"iso_name\"].agg(\"count\").reset_index()\n",
    "        present = ribo_seq_sub_w_jx[[\"iso_name\", \"status\"]].drop_duplicates().groupby([\"status\"])[\"iso_name\"].agg(\"count\").reset_index()\n",
    "        perc = tots.merge(present, on=[\"status\"], \n",
    "                          how=\"left\", suffixes=(\"_tot\", \"_present\"))\n",
    "        perc[\"percent\"] = (perc[\"iso_name_present\"]/perc[\"iso_name_tot\"])*100\n",
    "        perc[\"qcut\"] = qcut\n",
    "        perc[\"col\"] = col\n",
    "\n",
    "        qcut_percs = pd.concat([qcut_percs, perc])\n",
    "        \n",
    "qcut_percs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2.5, 1.75))\n",
    "ax = sns.barplot(data=qcut_percs[qcut_percs[\"col\"] == \"med_dev\"], x=\"qcut\", hue=\"status\", y=\"percent\",\n",
    "                 hue_order=[\"ref\", \"alt\", \"novel\"], palette=palette)\n",
    "ax.set_xlabel(\"RNA-Seq Expression Quartile\\n(1 = lowest, 4 = highest)\")\n",
    "ax.set_ylabel(\"Percent of isoforms with unique\\njunctions present in RiboSeq data\")\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "# Make 'qcut' and 'status' columns categorical\n",
    "qcut_percs[\"status\"] = pd.Categorical(qcut_percs[\"status\"], categories=[\"ref\", \"alt\", \"novel\"], ordered=True)\n",
    "sorted_qcuts = qcut_percs.sort_values(by=[\"status\", \"qcut\"])\n",
    "\n",
    "for bar, (_, row) in zip(ax.patches, sorted_qcuts[sorted_qcuts[\"col\"] == \"med_dev\"].iterrows()):\n",
    "    # Percentage value along the top of each bar\n",
    "    percent = f\"{row['percent']:.0f}%\"  # Format percentage\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        bar.get_height() + 0.5,  # Slightly above the bar\n",
    "        percent, \n",
    "        ha=\"center\", va=\"bottom\", fontsize=PAPER_FONTSIZE-2\n",
    "    )\n",
    "    \n",
    "    # n value along the bottom of each bar\n",
    "    n_value = row[\"iso_name_tot\"]  # Format n-value\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        0,  # bottom of bar\n",
    "        n_value, \n",
    "        color=\"white\",\n",
    "        ha=\"center\", va=\"bottom\", fontsize=PAPER_FONTSIZE-2\n",
    "    )\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "ax.set_yticks((0, 20, 40, 60, 80, 100))\n",
    "ax.set_yticklabels([\"%s%%\" % y for y in ax.get_yticks()])\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/RiboSeq_ExpressionQCut_MedDev.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2.5, 1.75))\n",
    "ax = sns.barplot(data=qcut_percs[qcut_percs[\"col\"] == \"med_gtex_ds\"], x=\"qcut\", hue=\"status\", y=\"percent\",\n",
    "                 hue_order=[\"ref\", \"alt\", \"novel\"], palette=palette)\n",
    "ax.set_xlabel(\"RNA-Seq Expression Quartile\\n(1 = lowest, 4 = highest)\")\n",
    "ax.set_ylabel(\"% of isoforms with unique\\njunctions present in RiboSeq data\")\n",
    "plt.legend(loc=2, bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "# Make 'qcut' and 'status' columns categorical\n",
    "qcut_percs[\"status\"] = pd.Categorical(qcut_percs[\"status\"], categories=[\"ref\", \"alt\", \"novel\"], ordered=True)\n",
    "sorted_qcuts = qcut_percs.sort_values(by=[\"status\", \"qcut\"])\n",
    "\n",
    "for bar, (_, row) in zip(ax.patches, sorted_qcuts[sorted_qcuts[\"col\"] == \"med_gtex_ds\"].iterrows()):\n",
    "    # Percentage value along the top of each bar\n",
    "    percent = f\"{row['percent']:.0f}%\"  # Format percentage\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        bar.get_height() + 0.5,  # Slightly above the bar\n",
    "        percent, \n",
    "        ha=\"center\", va=\"bottom\", fontsize=PAPER_FONTSIZE-2\n",
    "    )\n",
    "    \n",
    "    # n value along the bottom of each bar\n",
    "    n_value = row[\"iso_name_tot\"]  # Format n-value\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        0,  # bottom of bar\n",
    "        n_value, \n",
    "        color=\"white\",\n",
    "        ha=\"center\", va=\"bottom\", fontsize=PAPER_FONTSIZE-2\n",
    "    )\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "ax.set_yticks((0, 20, 40, 60, 80, 100))\n",
    "ax.set_yticklabels([\"%s%%\" % y for y in ax.get_yticks()])\n",
    "\n",
    "fig.savefig(\"../../figures/fig2/RiboSeq_ExpressionQCut_MedGtexDS.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. make supplemental files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_clones = {}\n",
    "\n",
    "for gene in clone_tfs:\n",
    "    gene_ref = clone_tfs[gene].cloned_reference_isoform.name\n",
    "    for iso in clone_tfs[gene].cloned_isoforms:\n",
    "        clone_name = iso.name\n",
    "        if not iso.ensembl_transcript_names is None:\n",
    "            tx_names = \"|\".join(iso.ensembl_transcript_names)\n",
    "            tx_ids = \"|\".join(iso.ensembl_transcript_ids)\n",
    "            if clone_name == gene_ref:\n",
    "                status = \"annotated reference\"\n",
    "            else:\n",
    "                status = \"annotated alternative\"\n",
    "        else:\n",
    "            tx_names = \"NA\"\n",
    "            tx_ids = \"NA\"\n",
    "            \n",
    "            if clone_name == gene_ref:\n",
    "                status = \"novel reference\"\n",
    "            else:\n",
    "                status = \"novel alternative\"\n",
    "        cds_seq = iso.clone_nt_seq\n",
    "        aa_seq = iso.aa_seq\n",
    "        supp_clones[clone_name] = {\"gene_symbol\": gene, \n",
    "                                   \"isoform_status\": status,\n",
    "                                   \"gencode_transcript_names\": tx_names,\n",
    "                                   \"ensembl_transcript_ids\": tx_ids, \n",
    "                                   \"cds_seq\": cds_seq,\n",
    "                                   \"aa_seq\": aa_seq}\n",
    "        \n",
    "supp_clones = pd.DataFrame.from_dict(supp_clones, \n",
    "                                     orient=\"index\").rename_axis(\"clone_id\").reset_index()\n",
    "supp_clones[\"isoform_status\"] = pd.Categorical(supp_clones[\"isoform_status\"], \n",
    "                                       [\"annotated reference\", \"novel reference\", \n",
    "                                        \"annotated alternative\",\n",
    "                                        \"novel alternative\"])\n",
    "supp_clones[\"tf_family\"] = supp_clones[\"gene_symbol\"].map(fam)\n",
    "\n",
    "supp_clones = supp_clones.sort_values(by=[\"clone_id\", \"isoform_status\"])\n",
    "print(\"NUMBER OF ISOS IN SUPP FILE: %s\" % (len(supp_clones.clone_id.unique())))\n",
    "print(\"NUMBER OF GENES IN SUPP FILE: %s\" % (len(supp_clones.gene_symbol.unique())))\n",
    "supp_clones.isoform_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_clones.to_csv(\"../../supp/SuppTable_CloneList.txt\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_clones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNA baits in Y1H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_baits = load_Y1H_DNA_bait_sequences()\n",
    "supp_baits = (pd.DataFrame.from_dict(supp_baits, orient=\"index\")\n",
    "              .rename_axis(\"bait_id\")\n",
    "              .reset_index())\n",
    "supp_baits.columns = [\"bait_id\", \"seq\"]\n",
    "supp_baits[\"bait_id\"] = supp_baits[\"bait_id\"].str.upper()\n",
    "\n",
    "# limit to baits that are in our y1h data\n",
    "supp_baits = supp_baits[supp_baits[\"bait_id\"].isin(baits)]\n",
    "print(\"NUM OF BAITS IN SUPP FILE: %s\" % len(supp_baits))\n",
    "\n",
    "supp_baits.to_csv(\"../../supp/SuppTable_DNABaits.txt\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y1H results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map clone_acc to clone_name\n",
    "clone_acc_map = {}\n",
    "\n",
    "for gene in clone_tfs:\n",
    "    for iso in clone_tfs[gene].cloned_isoforms:\n",
    "        clone_acc = iso.clone_acc\n",
    "        clone_name = iso.name\n",
    "        clone_acc_map[clone_acc] = clone_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_y1h = y1h.copy()\n",
    "supp_y1h[\"clone_id\"] = supp_y1h[\"clone_acc\"].map(clone_acc_map)\n",
    "supp_y1h = supp_y1h[[\"gene_symbol\", \"clone_id\"] + baits]\n",
    "\n",
    "print(\"NUM ISOS IN SUPP Y1H FILE: %s\" % (len(supp_y1h.clone_id.unique())))\n",
    "print(\"NUM GENES IN SUPP Y1H FILE: %s\" % (len(supp_y1h.gene_symbol.unique())))\n",
    "print(\"NUM BAITS IN SUPP Y1H FILE: %s\" % len(baits))\n",
    "supp_y1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_y1h.to_csv(\"../../supp/SuppTable_eY1HResults.txt\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y2H results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_y2h = load_full_y2h_data_including_controls()\n",
    "supp_y2h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload y2h since we loaded validation data above\n",
    "supp_y2h = load_full_y2h_data_including_controls()\n",
    "supp_y2h = supp_y2h.rename(columns={'ad_clone_name': 'ad_clone_id'})\n",
    "clones = load_valid_isoform_clones(include_single_isoform_genes=True)\n",
    "supp_y2h = supp_y2h.loc[\n",
    "    ~supp_y2h[\"category\"].isin([\"lit_bm_isoforms\", \"rrs_isoforms\"])\n",
    "    & supp_y2h['ad_clone_acc'].isin(clones[\"clone_acc\"].values),\n",
    "    [\n",
    "     'ad_clone_id',\n",
    "     'ad_gene_symbol',\n",
    "     'ad_orf_id',\n",
    "     'db_gene_symbol',\n",
    "     'db_orf_id',\n",
    "     'Y2H_result',\n",
    "     ]\n",
    "]\n",
    "print(\"NUM ISOS IN SUPP Y2H FILE: %s\" % (len(supp_y2h[\"ad_clone_id\"].unique())))\n",
    "print(\"NUM GENES IN SUPP Y2H FILE: %s\" % (len(supp_y2h['ad_gene_symbol'].unique())))\n",
    "print(\"NUM PARTNERS IN SUPP Y2H FILE: %s\" % len(supp_y2h['db_gene_symbol'].unique()))\n",
    "supp_y2h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the categories\n",
    "cats = load_ppi_partner_categories()\n",
    "cats.columns = [\"db_gene_symbol\", \"db_gene_category\", \"db_gene_cofactor_type\"]\n",
    "supp_y2h = supp_y2h.merge(cats, on=\"db_gene_symbol\", how=\"left\")\n",
    "supp_y2h[pd.isnull(supp_y2h[\"db_gene_category\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_y2h.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_y2h.db_gene_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_y2h.db_gene_cofactor_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_y2h.to_csv(\"../../supp/SuppTable_PairwiseY2HResults.txt\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1H results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload m1h since we summarized above\n",
    "m1h = load_m1h_activation_data()\n",
    "m1h['M1H_mean'] = m1h[['M1H_rep1', 'M1H_rep2', 'M1H_rep3']].mean(axis=1)\n",
    "supp_m1h = m1h.copy()\n",
    "supp_m1h[\"clone_id\"] = supp_m1h[\"clone_acc\"].map(clone_acc_map)\n",
    "supp_m1h = supp_m1h[[\"clone_id\", \"gene_symbol\", \"M1H_rep1\", \"M1H_rep2\", \"M1H_rep3\", \"M1H_mean\"]]\n",
    "\n",
    "print(\"NUM ISOS IN SUPP M1H FILE: %s\" % (len(supp_m1h.clone_id.unique())))\n",
    "print(\"NUM GENES IN SUPP M1H FILE: %s\" % (len(supp_m1h.gene_symbol.unique())))\n",
    "supp_m1h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_m1h.to_csv(\"../../supp/SuppTable_M1HResults.txt\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_n2h = load_n2h_ppi_validation_data()\n",
    "\n",
    "supp_n2h[\"clone_id\"] = supp_n2h[\"clone_acc\"].map(clone_acc_map)\n",
    "\n",
    "\n",
    "# drop vignettes, since we don't use them\n",
    "# unless we change and use it to mention CREB5-MAPK9\n",
    "supp_n2h = supp_n2h.loc[\n",
    "    ~supp_n2h['source'].isin({'vignettes'}),\n",
    "    [\n",
    "        'clone_id', \n",
    "        'gene_symbol_tf',\n",
    "        'gene_symbol_partner',\n",
    "        'test_orf_ida',\n",
    "        'test_orf_idb',\n",
    "        'source',\n",
    "        'score_pair',\n",
    "        'score_empty-N1',\n",
    "        'score_empty-N2',\n",
    "        'log2 NLR',\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "supp_n2h.to_csv(\"../../supp/SuppTable_N2HResults.txt\",\n",
    "                index=False,\n",
    "                sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDI validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_pdi_val = load_PDI_luciferase_validation_experiment()\n",
    "y1h = load_y1h_pdi_data()\n",
    "\n",
    "# update the interaction calls if needed\n",
    "new_calls = []\n",
    "for i, row in supp_pdi_val.iterrows():\n",
    "    clone = row[\"clone_acc\"]\n",
    "    bait = row[\"Bait\"]\n",
    "    orig_y1h_call = row['Interaction?']\n",
    "    \n",
    "    try:\n",
    "        updated_y1h_call = y1h[y1h['clone_acc'] == clone][bait].iloc[0]\n",
    "    except:\n",
    "        print(\"not found: clone: %s | bait: %s | orig call: %s\" % (clone, bait, orig_y1h_call))\n",
    "        updated_y1h_call = np.nan\n",
    "    new_calls.append(updated_y1h_call)\n",
    "\n",
    "supp_pdi_val[\"Y1H_result\"] = new_calls\n",
    "supp_pdi_val[\"clone_id\"] = supp_pdi_val[\"clone_acc\"].map(clone_acc_map)\n",
    "supp_pdi_val = supp_pdi_val.loc[pd.notnull(supp_pdi_val['Y1H_result']), \n",
    "    [\n",
    "        \"gene_symbol\",\n",
    "        \"clone_id\",\n",
    "        \"Bait\",\n",
    "        \"Y1H_result\",\n",
    "        'Replicate1', \n",
    "        'Replicate2',\n",
    "        'Replicate3', \n",
    "        'Average (empty-pEZY3-VP160)',\n",
    "        'Log2(FC)',\n",
    "    ]\n",
    "]\n",
    "supp_pdi_val.to_csv(\"../../supp/SuppTable_PDI_validation.txt\",\n",
    "                index=False,\n",
    "                sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pfam domains considered DNA binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_dbd = load_DNA_binding_domains()\n",
    "supp_dbd.to_csv(\"../../supp/SuppTable_DBD_definition.txt\",\n",
    "                index=False,\n",
    "                sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(2.5, 1))\n",
    "\n",
    "clone_tfs[\"SP2\"].exon_diagram(ax=ax)\n",
    "fig.savefig(\"../../figures/fig2/SP2_exons.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py38]",
   "language": "python",
   "name": "conda-env-.conda-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
