{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the `TF-iso_ref-vs-alt.tsv` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_loading import (load_annotated_6k_collection,\n",
    "                          load_y2h_isoform_data,\n",
    "                          load_y1h_pdi_data,\n",
    "                          load_m1h_activation_data,\n",
    "                          load_valid_isoform_clones,\n",
    "                          DIMERIZING_TF_FAMILIES)\n",
    "from isoform_pairwise_metrics import pairs_of_isoforms_comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from cache\n"
     ]
    }
   ],
   "source": [
    "tfs = load_annotated_6k_collection()\n",
    "\n",
    "m1h = load_m1h_activation_data()\n",
    "m1h['mean'] = m1h[['M1H_rep1', 'M1H_rep2', 'M1H_rep3']].mean(axis=1)\n",
    "m1h['abs_mean'] = m1h['mean'].abs()\n",
    "\n",
    "y1h = load_y1h_pdi_data()\n",
    "y1h = y1h.drop_duplicates(subset=['unique_acc'])  # TODO: move code to data loading\n",
    "y1h = y1h.set_index('unique_acc')  # TODO: move code to data loading\n",
    "\n",
    "y2h = load_y2h_isoform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isoform_pairwise_metrics import _pairs_comparison_table\n",
    "\n",
    "\n",
    "def pairs_of_ref_vs_alt_isoforms_comparison_table(tfs, y2h=None, y1h=None, m1h=None):\n",
    "    iso_pairs = []\n",
    "    for tf in tfs.values():\n",
    "        ref = tf.cloned_reference_isoform\n",
    "        for alt in tf.cloned_isoforms:\n",
    "            if alt.name == ref.name:\n",
    "                continue\n",
    "            iso_pairs.append((tf.name,\n",
    "                              tf.ensembl_gene_id,\n",
    "                              tf.tf_family,\n",
    "                              tf.tf_family in DIMERIZING_TF_FAMILIES,\n",
    "                              ref.clone_acc,\n",
    "                              alt.clone_acc,\n",
    "                              '|'.join(ref.ensembl_transcript_ids) if ref.ensembl_transcript_ids is not None else np.nan,\n",
    "                              '|'.join(alt.ensembl_transcript_ids) if alt.ensembl_transcript_ids is not None else np.nan,\n",
    "                              ref.is_novel_isoform(),\n",
    "                              alt.is_novel_isoform(),\n",
    "                              tf.cloned_MANE_select_isoform,\n",
    "                              len(ref.aa_seq),\n",
    "                              len(alt.aa_seq),\n",
    "                              len(ref.exons),\n",
    "                              len(alt.exons),\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"alternative N-terminal\"],\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"alternative C-terminal\"],\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"alternative internal exon\"],\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"alternative 5' splice site\"],\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"alternative 3' splice site\"],\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"exon skipping\"],\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"mutually exclusive exons\"],\n",
    "                              tf.splicing_categories(ref.name, alt.name)[\"intron retention\"],\n",
    "\n",
    "                              ))\n",
    "    iso_pairs = pd.DataFrame(\n",
    "        data=iso_pairs,\n",
    "        columns=[\"gene_symbol\",\n",
    "                 \"Ensembl_gene_ID\",\n",
    "                 \"family\",\n",
    "                 \"is_dimerizing_TF_family\",\n",
    "                 \"clone_acc_ref\",\n",
    "                 \"clone_acc_alt\",\n",
    "                 \"Ensembl_transcript_IDs_ref\",\n",
    "                 \"Ensembl_transcript_IDs_alt\",\n",
    "                 \"is_ref_novel_isoform\",\n",
    "                 \"is_alt_novel_isoform\",\n",
    "                 \"is_MANE_select_isoform_cloned\",\n",
    "                 \"n_aa_ref\",\n",
    "                 \"n_aa_alt\",\n",
    "                 \"n_exons_ref\",\n",
    "                 \"n_exons_alt\",\n",
    "                 \"is_alternative_N_terminal\",\n",
    "                 \"is_alternative_C_terminal\",\n",
    "                 \"is_alternative_internal_exon\",\n",
    "                 \"is_alternative_5_prime_donor\",\n",
    "                 \"is_alternative_3_prime_acceptor\",\n",
    "                 \"is_exon_skipping\",\n",
    "                 \"is_mutually_exclusive_exons\",\n",
    "                 \"is_intron_retention\",\n",
    "                 ]\n",
    "    )\n",
    "    return iso_pairs\n",
    "\n",
    "\n",
    "\n",
    "df = pairs_of_ref_vs_alt_isoforms_comparison_table(tfs, y2h=y2h, y1h=y1h, m1h=m1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBD intact\n",
    "from data_loading import load_dbd_accessions\n",
    "\n",
    "def load_dbd_affected():\n",
    "    df = pd.concat([g.aa_feature_disruption(g.cloned_reference_isoform.name) for g in tfs.values()])\n",
    "    df['is_DBD'] = df['accession'].isin(load_dbd_accessions())\n",
    "    df_new = (df.loc[df['is_DBD'], :]\n",
    "        .groupby(['gene', 'ref_iso', 'alt_iso'])\n",
    "        [['deletion', 'frameshift']].sum()\n",
    "        .sum(axis=1) / df.loc[df['is_DBD'], :]\n",
    "        .groupby(['gene', 'ref_iso', 'alt_iso'])\n",
    "        ['length'].sum()).to_frame(name='dbd_fraction')\n",
    "    df_new['dbd_insertion_n_aa'] = (df.loc[df['is_DBD'], :]\n",
    "                                  .groupby(['gene', 'ref_iso', 'alt_iso'])\n",
    "                                  ['insertion']\n",
    "                                  .sum())\n",
    "    df = df_new.reset_index()\n",
    "    df['dbd_pct_lost'] = df['dbd_fraction'] * 100.\n",
    "    df = df.drop(columns=['dbd_fraction'])\n",
    "    return df\n",
    "\n",
    "\n",
    "dbd = load_dbd_affected()\n",
    "dbd['clone_acc_ref'] = dbd['ref_iso'].map({iso.name: iso.clone_acc for tf in tfs.values() for iso in tf.cloned_isoforms})\n",
    "dbd['clone_acc_alt'] = dbd['alt_iso'].map({iso.name: iso.clone_acc for tf in tfs.values() for iso in tf.cloned_isoforms})\n",
    "dbd = dbd.drop(columns=['gene', 'ref_iso', 'alt_iso'])\n",
    "df = pd.merge(df, dbd, how='left', on=['clone_acc_ref', 'clone_acc_alt'])\n",
    "df['dbd_affected'] = df['dbd_pct_lost'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import load_seq_comparison_data\n",
    "\n",
    "aa_ident = load_seq_comparison_data()\n",
    "df[\"aa_seq_pct_id\"] = df.apply(\n",
    "    lambda x: \"_\".join(sorted([x[\"clone_acc_ref\"], x[\"clone_acc_alt\"]])), axis=1\n",
    ").map(aa_ident)\n",
    "if df['aa_seq_pct_id'].isnull().any():\n",
    "    raise UserWarning('Unexpected missing sequence similarity values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the assays\n",
    "\n",
    "# y2h n_positive_ref n_positive_ref_filtered n_shared_ref_alt\n",
    "# y2h n successfully tested in both\n",
    "# M1H at least one isoform of gene has |activation| >= 2 fold\n",
    "\n",
    "y2h_complete = load_y2h_isoform_data(require_at_least_one_ppi_per_isoform=False)\n",
    "n_ppi = y2h_complete.loc[(y2h_complete['Y2H_result'] == True), :].groupby('ad_clone_acc').size()\n",
    "df['n_positive_PPI_ref'] = df['clone_acc_ref'].map(n_ppi)\n",
    "df['n_positive_PPI_alt'] = df['clone_acc_alt'].map(n_ppi)\n",
    "# BUG MISSING 0's here!\n",
    "df.loc[df['n_positive_PPI_ref'].isnull() &\n",
    "       df['clone_acc_ref'].isin(y2h_complete.loc[(y2h_complete['Y2H_result'] == False), \n",
    "                              'ad_clone_acc'].unique()),\n",
    "       'n_positive_PPI_ref'] = 0\n",
    "df.loc[df['n_positive_PPI_alt'].isnull() &\n",
    "       df['clone_acc_alt'].isin(y2h_complete.loc[(y2h_complete['Y2H_result'] == False), \n",
    "                              'ad_clone_acc'].unique()),\n",
    "       'n_positive_PPI_alt'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isoform_pairwise_metrics import (\n",
    " number_tested_partners,\n",
    "  number_shared_partners,\n",
    "  jaccard_index)\n",
    "\n",
    "def ppi_metric(row, data, function, suffixes=('_a', '_b')):\n",
    "    ad_a = row[\"clone_acc\" + suffixes[0]]\n",
    "    ad_b = row[\"clone_acc\" + suffixes[1]]\n",
    "    pair = data.loc[data[\"ad_clone_acc\"].isin([ad_a, ad_b]), :].pivot(\n",
    "        values=\"Y2H_result\", index=\"db_gene_symbol\", columns=\"ad_clone_acc\"\n",
    "    )\n",
    "    if ad_a not in pair.columns or ad_b not in pair.columns:\n",
    "        return np.nan\n",
    "    # remove any partner with AA / NC / NS / NaN in either\n",
    "    pair = pair.loc[pair.notnull().all(axis=1), :].astype(int).astype(bool)\n",
    "    # remove partners that tested negative in both\n",
    "    pair = pair.loc[pair.any(axis=1), :]\n",
    "    if pair.shape[0] > 0:\n",
    "        return function(\n",
    "            set(pair.index[pair[ad_a]].values), set(pair.index[pair[ad_b]].values)\n",
    "        )\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['n_PPI_successfully_tested_in_ref_and_alt'] = df.apply(\n",
    "            ppi_metric, data=y2h_complete, suffixes=(\"_ref\", \"_alt\"), function=number_tested_partners, axis=1\n",
    "        )\n",
    "df['n_positive_PPI_ref_filtered'] = df.apply(\n",
    "            ppi_metric, data=y2h_complete, suffixes=(\"_ref\", \"_alt\"), function=lambda a, b: len(a), axis=1\n",
    "        )\n",
    "df['n_positive_PPI_alt_filtered'] = df.apply(\n",
    "            ppi_metric, data=y2h_complete, suffixes=(\"_ref\", \"_alt\"), function=lambda a, b: len(b), axis=1\n",
    "        )\n",
    "df['n_shared_PPI'] = df.apply(\n",
    "            ppi_metric, data=y2h_complete, suffixes=(\"_ref\", \"_alt\"), function=number_shared_partners, axis=1\n",
    "        )\n",
    "df['PPI_jaccard'] = df.apply(\n",
    "            ppi_metric, data=y2h_complete, suffixes=(\"_ref\", \"_alt\"), function=jaccard_index, axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import load_tf_families\n",
    "from data_loading import load_human_tf_db\n",
    "from data_loading import load_ppi_partner_categories\n",
    "\n",
    "\n",
    "ppi_partner_cats = load_ppi_partner_categories()\n",
    "tfdb = load_human_tf_db()\n",
    "fam = load_tf_families()\n",
    "y2h['ad_tf_family'] = y2h['ad_gene_symbol'].map(fam)\n",
    "y2h['db_tf_family'] = y2h['db_gene_symbol'].map(fam)\n",
    "y2h['is_dimerizing_ppi'] = (y2h['ad_tf_family'].isin(DIMERIZING_TF_FAMILIES) &\n",
    "                        (y2h['ad_tf_family'] == y2h['db_tf_family']))\n",
    "y2h['is_tf_tf_ppi'] = y2h['db_gene_symbol'].isin(tfdb['HGNC symbol'].unique())\n",
    "\n",
    "# of reference dimer PPI, are all lost, some lost, none lost\n",
    "def ppi_pertubation(row, ppi):\n",
    "    ref_clone_acc = row['clone_acc_ref']\n",
    "    alt_clone_acc = row['clone_acc_alt']\n",
    "    if ref_clone_acc not in ppi['ad_clone_acc'].unique() or alt_clone_acc not in ppi['ad_clone_acc'].unique():\n",
    "        return np.nan\n",
    "    df = (ppi.loc[ppi['ad_clone_acc'].isin([ref_clone_acc, alt_clone_acc]),\n",
    "                  ['ad_clone_acc', 'db_gene_symbol', 'Y2H_result']]\n",
    "            .pivot(values='Y2H_result', index='db_gene_symbol', columns='ad_clone_acc')\n",
    "            .dropna())\n",
    "    df = df.loc[df.any(axis=1), :]\n",
    "    if df.shape[0] == 0:\n",
    "        return np.nan\n",
    "    if df.all().all():\n",
    "        return 'retains all'\n",
    "    elif not df[alt_clone_acc].any():\n",
    "        return 'loses all'\n",
    "    elif df[alt_clone_acc].sum() > df[ref_clone_acc].sum():\n",
    "        return 'gains some'\n",
    "    else:\n",
    "        return 'loses some'\n",
    "\n",
    "df['dimer_ppi'] = df.apply(ppi_pertubation, \n",
    "                           ppi=y2h.loc[y2h['is_dimerizing_ppi'], :],\n",
    "                           axis=1)\n",
    "df['other_than_dimer_ppi'] = df.apply(ppi_pertubation, \n",
    "                           ppi=y2h.loc[~y2h['is_dimerizing_ppi'], :],\n",
    "                           axis=1)\n",
    "df['tf_tf_ppi'] = df.apply(ppi_pertubation, \n",
    "                           ppi=y2h.loc[y2h['is_tf_tf_ppi'], :],\n",
    "                           axis=1)\n",
    "\n",
    "                           \n",
    "df['tf_cofactor_ppi'] = df.apply(ppi_pertubation, \n",
    "                           ppi=y2h.loc[y2h['db_gene_symbol'].isin(ppi_partner_cats.loc[ppi_partner_cats['category'] == 'cofactor', 'partner'].unique()) &\n",
    "                                       ~y2h['is_tf_tf_ppi'], :],\n",
    "                           axis=1)\n",
    "df['tf_signalling_ppi'] = df.apply(ppi_pertubation, \n",
    "                           ppi=y2h.loc[y2h['db_gene_symbol'].isin(ppi_partner_cats.loc[ppi_partner_cats['category'].isin(['cell cycle', 'protein traffiking', 'protein turnover', 'signaling', 'cell-cell signaling']), 'partner'].unique()) &\n",
    "                                       ~y2h['is_tf_tf_ppi'] &\n",
    "                                       ~y2h['db_gene_symbol'].isin(ppi_partner_cats.loc[ppi_partner_cats['category'] == 'cofactor', 'partner'].unique()), :],\n",
    "                           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdi_metric(row, data, function, suffixes=('_a', '_b')):\n",
    "    clone_acc_a = row[\"clone_acc\" + suffixes[0]]\n",
    "    clone_acc_b = row[\"clone_acc\" + suffixes[1]]\n",
    "    df = data.loc[\n",
    "        (data.index == clone_acc_a)\n",
    "        | (data.index == clone_acc_b),\n",
    "        data.columns[1:],\n",
    "    ].copy()\n",
    "    if df.shape[0] < 2:\n",
    "        return np.nan\n",
    "    df = df.loc[[clone_acc_a, clone_acc_b], df.any(axis=0)]\n",
    "    if df.shape[1] == 0:\n",
    "        return np.nan\n",
    "    # kaia edited these 2 lines to drop any baits with NA\n",
    "    # my version of pandas wasn't auto-filtering these out, think it got fixed in later versions\n",
    "    a = set(df.columns[df.iloc[0].fillna(False)])\n",
    "    b = set(df.columns[df.iloc[1].fillna(False)])\n",
    "    return function(a, b)\n",
    "\n",
    "n_pdi = y1h.drop(columns=['tf']).sum(axis=1)\n",
    "df['n_positive_PDI_ref'] = df['clone_acc_ref'].map(n_pdi)\n",
    "df['n_positive_PDI_alt'] = df['clone_acc_alt'].map(n_pdi)\n",
    "df['n_PDI_successfully_tested_in_ref_and_alt'] = df.apply(\n",
    "            pdi_metric, data=y1h, suffixes=(\"_ref\", \"_alt\"), function=number_tested_partners, axis=1\n",
    "        )\n",
    "\n",
    "df['n_positive_PDI_ref_filtered'] = df.apply(\n",
    "            pdi_metric, data=y1h, suffixes=(\"_ref\", \"_alt\"), function=lambda a, b: len(a), axis=1\n",
    "        )\n",
    "df['n_positive_PDI_alt_filtered'] = df.apply(\n",
    "            pdi_metric, data=y1h, suffixes=(\"_ref\", \"_alt\"), function=lambda a, b: len(b), axis=1\n",
    "        )\n",
    "\n",
    "\n",
    "df['n_shared_PDI'] = df.apply(\n",
    "            pdi_metric, data=y1h, suffixes=(\"_ref\", \"_alt\"), function=number_shared_partners, axis=1\n",
    "        )\n",
    "df['PDI_jaccard'] = df.apply(\n",
    "            pdi_metric, data=y1h, suffixes=(\"_ref\", \"_alt\"), function=jaccard_index, axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['at_least_one_isoform_in_gene_abs_activation_gte_2fold'] = df['gene_symbol'].map(m1h.groupby('gene')['abs_mean'].max() >= 1)\n",
    "df['activation_ref'] = df['clone_acc_ref'].map(m1h.set_index('clone_acc')['mean'])\n",
    "df['activation_alt'] = df['clone_acc_alt'].map(m1h.set_index('clone_acc')['mean'])\n",
    "df['activation_fold_change_log2'] = (df['activation_alt'] - df['activation_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../output/TF-iso_ref-vs-alt.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ae04c9a3e8cbfaaf818a59204fe953064ae0593c0d7ed4865e22581ae0526ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
